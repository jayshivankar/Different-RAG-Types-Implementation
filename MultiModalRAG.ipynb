{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-text-splitters langchain-openai fitz\n"
      ],
      "metadata": {
        "id": "Hfxw7-V70pzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3e8f29d-2f11-46b7-fccd-96d9cb84a0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.9/425.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain-opentutorial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0RZWvSWsay_",
        "outputId": "329ad69f-e909-4140-df05-c40da9324328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-opentutorial\n",
            "  Downloading langchain_opentutorial-0.0.9-py3-none-any.whl.metadata (612 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from langchain-opentutorial) (2.32.4)\n",
            "Requirement already satisfied: langchain-openai>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-opentutorial) (1.1.10)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.13 in /usr/local/lib/python3.12/dist-packages (from langchain-openai>=0.2.0->langchain-opentutorial) (1.2.13)\n",
            "Requirement already satisfied: openai<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai>=0.2.0->langchain-opentutorial) (2.21.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai>=0.2.0->langchain-opentutorial) (0.12.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->langchain-opentutorial) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->langchain-opentutorial) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->langchain-opentutorial) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->langchain-opentutorial) (2026.1.4)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain-openai>=0.2.0->langchain-opentutorial) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain-openai>=0.2.0->langchain-opentutorial) (0.7.3)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain-openai>=0.2.0->langchain-opentutorial) (26.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain-openai>=0.2.0->langchain-opentutorial) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain-openai>=0.2.0->langchain-opentutorial) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain-openai>=0.2.0->langchain-opentutorial) (9.1.4)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain-openai>=0.2.0->langchain-opentutorial) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.13->langchain-openai>=0.2.0->langchain-opentutorial) (0.14.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai>=0.2.0->langchain-opentutorial) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai>=0.2.0->langchain-opentutorial) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai>=0.2.0->langchain-opentutorial) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai>=0.2.0->langchain-opentutorial) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai>=0.2.0->langchain-opentutorial) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai>=0.2.0->langchain-opentutorial) (4.67.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai>=0.2.0->langchain-opentutorial) (2025.11.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=2.20.0->langchain-openai>=0.2.0->langchain-opentutorial) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=2.20.0->langchain-openai>=0.2.0->langchain-opentutorial) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.13->langchain-openai>=0.2.0->langchain-opentutorial) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-openai>=0.2.0->langchain-opentutorial) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-openai>=0.2.0->langchain-opentutorial) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-openai>=0.2.0->langchain-opentutorial) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain-openai>=0.2.0->langchain-opentutorial) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.13->langchain-openai>=0.2.0->langchain-opentutorial) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.13->langchain-openai>=0.2.0->langchain-opentutorial) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.13->langchain-openai>=0.2.0->langchain-opentutorial) (0.4.2)\n",
            "Downloading langchain_opentutorial-0.0.9-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: langchain-opentutorial\n",
            "Successfully installed langchain-opentutorial-0.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-core langchain-openai langchain-classic langchain-community langchain-chroma"
      ],
      "metadata": {
        "id": "TLrUx5etgrkI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d1e7020-bed1-45d1-a0fc-79719b0e4376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.13)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.10)\n",
            "Collecting langchain-classic\n",
            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-1.1.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.7.3)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (26.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.4)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.14.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.21.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic) (1.1.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic) (2.32.4)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic) (2.0.46)\n",
            "Collecting requests<3.0.0,>=2.0.0 (from langchain-classic)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting chromadb<2.0.0,>=1.3.5 (from langchain-chroma)\n",
            "  Downloading chromadb-1.5.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting build>=1.0.3 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading build-1.4.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting pybase64>=1.4.1 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.40.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.38.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.38.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.22.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading pypika-0.51.1-py2.py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.67.3)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.78.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.23.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading kubernetes-35.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.11.7)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.26.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3.0.0,>=1.4.0->langchain-classic) (3.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.30.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.0.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (25.12.19)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (5.29.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (8.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.72.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.3.5->langchain-chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.5.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.0.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.7.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.3.5->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.21.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.23.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb<2.0.0,>=1.3.5->langchain-chroma) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.3.5->langchain-chroma) (1.3.0)\n",
            "Downloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_chroma-1.1.0-py3-none-any.whl (12 kB)\n",
            "Downloading chromadb-1.5.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.4.0-py3-none-any.whl (24 kB)\n",
            "Downloading kubernetes-35.0.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypika-0.51.1-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: pypika, durationpy, requests, pyproject_hooks, pybase64, opentelemetry-proto, mypy-extensions, marshmallow, bcrypt, backoff, typing-inspect, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, build, opentelemetry-semantic-conventions, kubernetes, dataclasses-json, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, langchain-classic, langchain-community, chromadb, langchain-chroma\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.38.0\n",
            "    Uninstalling opentelemetry-proto-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.38.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.38.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.38.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.38.0\n",
            "    Uninstalling opentelemetry-api-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.38.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.59b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.59b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.59b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.38.0\n",
            "    Uninstalling opentelemetry-sdk-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.38.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.38.0 requires opentelemetry-exporter-otlp-proto-common==1.38.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.38.0 requires opentelemetry-proto==1.38.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.38.0 requires opentelemetry-sdk~=1.38.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.4.0 chromadb-1.5.0 dataclasses-json-0.6.7 durationpy-0.10 kubernetes-35.0.0 langchain-chroma-1.1.0 langchain-classic-1.0.1 langchain-community-0.4.1 marshmallow-3.26.2 mypy-extensions-1.1.0 onnxruntime-1.24.1 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-grpc-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 posthog-5.4.0 pybase64-1.4.3 pypika-0.51.1 pyproject_hooks-1.2.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf tabula-py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWhbktjVa8PQ",
        "outputId": "57b6f7be-0d5b-467d-dab5-0f49ed01f9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.27.1-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting tabula-py\n",
            "  Downloading tabula_py-2.10.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.12/dist-packages (from tabula-py) (2.2.2)\n",
            "Requirement already satisfied: numpy>1.24.4 in /usr/local/lib/python3.12/dist-packages (from tabula-py) (2.0.2)\n",
            "Requirement already satisfied: distro in /usr/local/lib/python3.12/dist-packages (from tabula-py) (1.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25.3->tabula-py) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25.3->tabula-py) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25.3->tabula-py) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py) (1.17.0)\n",
            "Downloading pymupdf-1.27.1-cp310-abi3-manylinux_2_28_x86_64.whl (24.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabula_py-2.10.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf, tabula-py\n",
            "Successfully installed pymupdf-1.27.1 tabula-py-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "import json\n",
        "import logging # Added import for logging\n",
        "import warnings # Added import for warnings\n",
        "from typing import List, Dict, Any\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "\n",
        "# Make sure these imports are at the top of your file\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from openai import OpenAI\n",
        "from tqdm import tqdm\n",
        "import tabula\n",
        "import fitz\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.ERROR)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "tMb7MDez9ToP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04VBp9N9vXFf"
      },
      "outputs": [],
      "source": [
        "# # Install Pytorch & other libraries\n",
        "# %pip install \"torch>=2.4.0\"\n",
        "\n",
        "# # Install a transformers version that supports Gemma 3 (>= 4.51.3)\n",
        "# %pip install \"transformers>=4.51.3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dov_xE69vOvs"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Login into Hugging Face Hub\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23FZr1a5CBTS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a684230f-825a-448f-c63f-8db256939f9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully: data/attention_paper.pdf\n"
          ]
        }
      ],
      "source": [
        "# Downloading the dataset - URL of the \"Attention Is All You Need\" paper (Replace it with the URL of the PDF file/dataset you want to download)\n",
        "url = \"https://arxiv.org/pdf/1706.03762.pdf\"\n",
        "\n",
        "# Set the filename and filepath\n",
        "filename = \"attention_paper.pdf\"\n",
        "filepath = os.path.join(\"data\", filename)\n",
        "\n",
        "# Create the data directory if it doesn't exist\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "# Download the file\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    with open(filepath, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f\"File downloaded successfully: {filepath}\")\n",
        "else:\n",
        "    print(f\"Failed to download the file. Status code: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "DluWTcp57O91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "\n",
        "def create_directories(base_dir):\n",
        "    for d in [\"images\", \"text\", \"tables\"]:\n",
        "        os.makedirs(os.path.join(base_dir, d), exist_ok=True)\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# OPENAI HELPERS\n",
        "# -------------------------------------------------\n",
        "\n",
        "def summarize_table_openai(table_text):\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        input=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"You are an assistant tasked with summarizing tables and text for retrieval. \\\n",
        "    These summaries will be embedded and used to retrieve the raw text or table elements. \\\n",
        "    Give a concise summary of the table or text that is well-optimized for retrieval. Table \\\n",
        "    or text: {table_text} \"\n",
        "            }\n",
        "        ],\n",
        "        max_output_tokens=150\n",
        "    )\n",
        "    return response.output_text\n",
        "\n",
        "\n",
        "def summarize_image_openai(encoded_image):\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-4o\",\n",
        "        input=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"input_image\",\n",
        "                        \"image_url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"input_text\",\n",
        "                        \"text\": \"You are an assistant tasked with summarizing images for retrieval. \\\n",
        "                                These summaries will be embedded and used to retrieve the raw image. \\\n",
        "                                Give a concise summary of the image that is well optimized for retrieval.\"\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        max_output_tokens=120\n",
        "    )\n",
        "    # The Responses API returns response.output_text as a direct helper\n",
        "    return response.output_text\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# TABLE PROCESSING\n",
        "# -------------------------------------------------\n",
        "\n",
        "def process_tables(page_num, base_dir, items, filepath):\n",
        "    try:\n",
        "        tables = tabula.read_pdf(\n",
        "            filepath,\n",
        "            pages=\"all\",\n",
        "            multiple_tables=True\n",
        "        )\n",
        "\n",
        "        if not tables:\n",
        "            return\n",
        "\n",
        "        for idx, df in enumerate(tables):\n",
        "            table_text = df.to_markdown(index=False)\n",
        "\n",
        "            table_path = (\n",
        "                f\"{base_dir}/tables/\"\n",
        "                f\"{os.path.basename(filepath)}_table_{page_num}_{idx}.txt\"\n",
        "            )\n",
        "\n",
        "            with open(table_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(table_text)\n",
        "\n",
        "            summary = summarize_table_openai(table_text)\n",
        "\n",
        "            items.append({\n",
        "                \"page\": page_num,\n",
        "                \"type\": \"table\",\n",
        "                \"text\": table_text,\n",
        "                \"summary\": summary,\n",
        "                \"path\": table_path\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[Table Error] Page {page_num}: {e}\")\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# TEXT PROCESSING (unchanged)\n",
        "# -------------------------------------------------\n",
        "\n",
        "def process_text_chunks(text, splitter, page_num, base_dir, items, filepath):\n",
        "    chunks = splitter.split_text(text)\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        text_path = (\n",
        "            f\"{base_dir}/text/\"\n",
        "            f\"{os.path.basename(filepath)}_text_{page_num}_{i}.txt\"\n",
        "        )\n",
        "\n",
        "        with open(text_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(chunk)\n",
        "\n",
        "        items.append({\n",
        "            \"page\": page_num,\n",
        "            \"type\": \"text\",\n",
        "            \"text\": chunk,\n",
        "            \"path\": text_path\n",
        "        })\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# IMAGE PROCESSING\n",
        "# -------------------------------------------------\n",
        "\n",
        "def process_images(doc, page, page_num, base_dir, items, filepath):\n",
        "    images = page.get_images(full=True)\n",
        "\n",
        "    for idx, img in enumerate(images):\n",
        "        xref = img[0]\n",
        "        pix = fitz.Pixmap(doc, xref)\n",
        "\n",
        "        if pix.alpha:\n",
        "            pix = fitz.Pixmap(fitz.csRGB, pix)\n",
        "\n",
        "        image_path = (\n",
        "            f\"{base_dir}/images/\"\n",
        "            f\"{os.path.basename(filepath)}_image_{page_num}_{idx}_{xref}.png\"\n",
        "        )\n",
        "\n",
        "        pix.save(image_path)\n",
        "        pix = None\n",
        "\n",
        "        with open(image_path, \"rb\") as f:\n",
        "            encoded = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "        summary = summarize_image_openai(encoded)\n",
        "\n",
        "        items.append({\n",
        "            \"page\": page_num,\n",
        "            \"type\": \"image\",\n",
        "            \"path\": image_path,\n",
        "            \"image\": encoded,\n",
        "            \"summary\": summary\n",
        "        })\n"
      ],
      "metadata": {
        "id": "05txR1jR7ZPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-text-splitters langchain-openai\n"
      ],
      "metadata": {
        "id": "qKszqXyd7gm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPYScVqlmKkU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7773db1-99af-4494-ac60-461a7095e931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDF pages:   0%|          | 0/15 [00:00<?, ?it/s]WARNING:tabula.backend:Failed to import jpype dependencies. Fallback to subprocess.\n",
            "WARNING:tabula.backend:No module named 'jpype'\n",
            "WARNING:tabula.backend:Got stderr: Feb 19, 2026 9:33:03 AM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider loadDiskCache\n",
            "WARNING: New fonts found, font cache will be re-built\n",
            "Feb 19, 2026 9:33:03 AM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider <init>\n",
            "WARNING: Building on-disk font cache, this may take a while\n",
            "Feb 19, 2026 9:33:03 AM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider <init>\n",
            "WARNING: Finished building on-disk font cache, found 17 fonts\n",
            "Feb 19, 2026 9:33:03 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Feb 19, 2026 9:33:03 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Feb 19, 2026 9:33:12 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font THPNLT+CMEX9\n",
            "\n",
            "Processing PDF pages:   7%|▋         | 1/15 [00:54<12:41, 54.37s/it]WARNING:tabula.backend:Got stderr: Feb 19, 2026 9:33:57 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Feb 19, 2026 9:33:57 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Feb 19, 2026 9:34:01 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font THPNLT+CMEX9\n",
            "\n",
            "Processing PDF pages:  13%|█▎        | 2/15 [01:29<09:20, 43.14s/it]WARNING:tabula.backend:Got stderr: Feb 19, 2026 9:34:32 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Feb 19, 2026 9:34:32 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Feb 19, 2026 9:34:37 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font THPNLT+CMEX9\n",
            "\n",
            "Processing PDF pages:  20%|██        | 3/15 [02:07<08:06, 40.57s/it]WARNING:tabula.backend:Got stderr: Feb 19, 2026 9:35:09 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Feb 19, 2026 9:35:09 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Feb 19, 2026 9:35:14 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font THPNLT+CMEX9\n",
            "\n",
            "Processing PDF pages:  27%|██▋       | 4/15 [02:52<07:47, 42.52s/it]WARNING:tabula.backend:Got stderr: Feb 19, 2026 9:35:55 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Feb 19, 2026 9:35:55 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Feb 19, 2026 9:36:00 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font THPNLT+CMEX9\n",
            "\n",
            "Processing PDF pages:  33%|███▎      | 5/15 [03:23<06:22, 38.22s/it]WARNING:tabula.backend:Got stderr: Feb 19, 2026 9:36:25 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Feb 19, 2026 9:36:25 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Feb 19, 2026 9:36:29 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font THPNLT+CMEX9\n",
            "\n",
            "Processing PDF pages:  40%|████      | 6/15 [03:54<05:21, 35.68s/it]WARNING:tabula.backend:Got stderr: Feb 19, 2026 9:36:56 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Feb 19, 2026 9:36:56 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Feb 19, 2026 9:37:01 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font THPNLT+CMEX9\n",
            "\n",
            "Processing PDF pages:  47%|████▋     | 7/15 [04:25<04:35, 34.39s/it]WARNING:tabula.backend:Got stderr: Feb 19, 2026 9:37:28 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Feb 19, 2026 9:37:28 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Feb 19, 2026 9:37:32 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font THPNLT+CMEX9\n",
            "\n",
            "Processing PDF pages:  53%|█████▎    | 8/15 [05:00<04:01, 34.54s/it]WARNING:tabula.backend:Got stderr: Feb 19, 2026 9:38:03 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Feb 19, 2026 9:38:03 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Feb 19, 2026 9:38:06 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font THPNLT+CMEX9\n",
            "\n",
            "Processing PDF pages:  60%|██████    | 9/15 [05:32<03:21, 33.61s/it]WARNING:tabula.backend:Got stderr: Feb 19, 2026 9:38:35 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Feb 19, 2026 9:38:35 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Feb 19, 2026 9:38:39 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font THPNLT+CMEX9\n",
            "\n",
            "Processing PDF pages:  67%|██████▋   | 10/15 [06:05<02:47, 33.58s/it]WARNING:tabula.backend:Got stderr: Feb 19, 2026 9:39:08 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Feb 19, 2026 9:39:08 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Feb 19, 2026 9:39:13 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font THPNLT+CMEX9\n",
            "\n",
            "Processing PDF pages:  73%|███████▎  | 11/15 [06:36<02:10, 32.71s/it]WARNING:tabula.backend:Got stderr: Feb 19, 2026 9:39:38 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Feb 19, 2026 9:39:38 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Feb 19, 2026 9:39:42 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font THPNLT+CMEX9\n",
            "\n",
            "Processing PDF pages:  80%|████████  | 12/15 [07:08<01:37, 32.48s/it]WARNING:tabula.backend:Got stderr: Feb 19, 2026 9:40:11 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Feb 19, 2026 9:40:11 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Feb 19, 2026 9:40:15 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font THPNLT+CMEX9\n",
            "\n",
            "Processing PDF pages:  87%|████████▋ | 13/15 [07:44<01:06, 33.44s/it]WARNING:tabula.backend:Got stderr: Feb 19, 2026 9:40:46 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Feb 19, 2026 9:40:46 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Feb 19, 2026 9:40:51 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font THPNLT+CMEX9\n",
            "\n",
            "Processing PDF pages:  93%|█████████▎| 14/15 [08:16<00:33, 33.02s/it]WARNING:tabula.backend:Got stderr: Feb 19, 2026 9:41:18 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font Symbol\n",
            "Feb 19, 2026 9:41:18 AM org.apache.pdfbox.pdmodel.font.PDType1Font <init>\n",
            "WARNING: Using fallback font LiberationSans for base font ZapfDingbats\n",
            "Feb 19, 2026 9:41:22 AM org.apache.pdfbox.pdmodel.font.PDSimpleFont toUnicode\n",
            "WARNING: No Unicode mapping for summationtext (80) in font THPNLT+CMEX9\n",
            "\n",
            "Processing PDF pages: 100%|██████████| 15/15 [08:48<00:00, 35.26s/it]\n"
          ]
        }
      ],
      "source": [
        "import fitz\n",
        "from tqdm import tqdm\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "doc = fitz.open(filepath)\n",
        "num_pages = len(doc)\n",
        "base_dir = \"data\"\n",
        "\n",
        "# Creating the directories\n",
        "create_directories(base_dir)\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=700,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len\n",
        ")\n",
        "\n",
        "items = []\n",
        "\n",
        "# Process each page of the PDF\n",
        "for page_num in tqdm(range(num_pages), desc=\"Processing PDF pages\"):\n",
        "    page = doc[page_num]\n",
        "    text = page.get_text()\n",
        "\n",
        "    process_tables(page_num, base_dir, items, filepath)\n",
        "    process_text_chunks(text, splitter, page_num, base_dir, items, filepath)\n",
        "    process_images(doc, page, page_num, base_dir, items, filepath)\n",
        "\n",
        "doc.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC4slk2UTWNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd82106a-3044-405c-83f4-103fce8192cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'page': 0,\n",
              " 'type': 'text',\n",
              " 'text': 'Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or',\n",
              " 'path': 'data/text/attention_paper.pdf_text_0_0.txt'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "text_list = [item for item in items if item['type'] == 'text']\n",
        "text_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auTWbmBORcfL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d799642a-124c-424f-c632-41c3cc628891"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'page': 0,\n",
              " 'type': 'text',\n",
              " 'text': 'training for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head',\n",
              " 'path': 'data/text/attention_paper.pdf_text_0_3.txt'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "text_list[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adK3QirOUMfT"
      },
      "outputs": [],
      "source": [
        "image_list = [item for item in items if item['type'] == 'image']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfvB1_eEUWap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3854dd15-8c5f-45df-bc9c-23f7b1781252"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'page': 3,\n",
              " 'type': 'image',\n",
              " 'path': 'data/images/attention_paper.pdf_image_3_0_182.png',\n",
              " 'image': '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',\n",
              " 'summary': 'Diagram of a Transformer attention mechanism: Flow starts with inputs Q and K through a MatMul, followed by Scale, optional Mask, SoftMax, and another MatMul with input V.'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "image_list[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ytt9MGkUZKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502d18bd-ee46-4098-f630-e25016dd21c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'page': 0,\n",
              " 'type': 'table',\n",
              " 'text': '| chose this function because we hypothesized it would allow the model to easily learn to attend by    |\\n|:-----------------------------------------------------------------------------------------------------|\\n| relative positions, since for any fixed offset k, PEpos+k can be represented as a linear function of |\\n| PEpos.                                                                                               |\\n| We also experimented with using learned positional embeddings [9] instead, and found that the two    |\\n| versions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version    |',\n",
              " 'summary': 'Summary: The text explains the choice of a sinusoidal positional encoding function, hypothesizing it helps the model learn relative positions since PE at position pos+k can be linearly derived from PE at pos. It notes that learned positional embeddings were also tested, yielding nearly identical results (referenced in Table 3 row E), but the sinusoidal version was preferred.',\n",
              " 'path': 'data/tables/attention_paper.pdf_table_0_1.txt'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "table_list = [item for item in items if item['type'] == 'table']\n",
        "table_list[1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_summaries = [text['text'] for text in text_list]\n",
        "table_summaries = [table['summary'] for table in table_list]\n",
        "image_summaries = [image['summary'] for image in image_list]"
      ],
      "metadata": {
        "id": "rQ0Fqwki3Onx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [text['text'] for text in text_list]\n",
        "tables = [table['text'] for table in table_list]\n",
        "images = [image['image'] for image in image_list]"
      ],
      "metadata": {
        "id": "tp30TyuF3d6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "# Using updated import paths\n",
        "from langchain_core.documents import Document\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_classic.retrievers import MultiVectorRetriever\n",
        "from langchain_core.stores import InMemoryStore\n",
        "from langchain_community.vectorstores import Chroma\n",
        "import os\n",
        "\n",
        "\n",
        "store = InMemoryStore()\n",
        "id_key = \"doc_id\"\n",
        "vectorstore = Chroma(\n",
        "    collection_name=\"mm_rag_mistral\",\n",
        "    embedding_function = OpenAIEmbeddings(),\n",
        ")\n",
        "\n",
        "retriever = MultiVectorRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=store,\n",
        "    id_key=id_key,\n",
        "    search_type=\"mmr\",\n",
        "    search_kwargs={\"k\": 5, \"fetch_k\": 10}\n",
        "  )\n",
        "\n",
        "def add_documents(retriever, doc_summaries, doc_contents):\n",
        "  doc_ids = [str(uuid.uuid4()) for _ in doc_contents]\n",
        "  summary_docs = [\n",
        "            Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
        "            for i, s in enumerate(doc_summaries)\n",
        "        ]\n",
        "\n",
        "  retriever.vectorstore.add_documents(summary_docs)\n",
        "        # mset maps IDs to the raw content (text or base64 string)\n",
        "  retriever.docstore.mset(list(zip(doc_ids, doc_contents)))\n",
        "\n",
        "\n",
        "if text_summaries:\n",
        "  add_documents(retriever, text_summaries, texts)\n",
        "if table_summaries:\n",
        "  add_documents(retriever, table_summaries, tables)\n",
        "if image_summaries:\n",
        "  add_documents(retriever, image_summaries, images)\n",
        "\n"
      ],
      "metadata": {
        "id": "jQyafWx99uoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a498b01-0e95-49a7-fa3f-17102dde3c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3164482691.py:13: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
            "  vectorstore = Chroma(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "relevant_chunks = retriever.vectorstore.similarity_search(\n",
        "    \"Can you tell me about Figure 1: The Transformer - model architecture.?\"\n",
        ")\n",
        "print(f\"Number of retrieved documents: {len(relevant_chunks)}\")\n"
      ],
      "metadata": {
        "id": "8_Rm2y-3V4kB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ee4bb0d-b564-4bd3-8978-a9bc7254e9ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of retrieved documents: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in relevant_chunks:\n",
        "    print(chunk.page_content, end=\"\\n\\n\")\n",
        "    print(\">\" * 100, end=\"\\n\\n\")"
      ],
      "metadata": {
        "id": "9kdV7gGLitWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6edcb062-d755-47c7-e065-800f9f31712f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figure 1: The Transformer - model architecture.\n",
            "The Transformer follows this overall architecture using stacked self-attention and point-wise, fully\n",
            "connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\n",
            "respectively.\n",
            "3.1\n",
            "Encoder and Decoder Stacks\n",
            "Encoder:\n",
            "The encoder is composed of a stack of N = 6 identical layers. Each layer has two\n",
            "sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\n",
            "wise fully connected feed-forward network. We employ a residual connection [11] around each of\n",
            "the two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "\n",
            "Transformer architecture diagram showing encoder and decoder stacks with components: input/output embeddings, positional encoding, multi-head attention, feed forward layers, and output probabilities.\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "\n",
            "Diagram of a Transformer model's multi-head attention mechanism, showing linear layers for V (value), K (key), and Q (query) inputs. Includes scaled dot-product attention, concatenation, and a final linear layer.\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "\n",
            "language modeling tasks [34].\n",
            "To the best of our knowledge, however, the Transformer is the first transduction model relying\n",
            "entirely on self-attention to compute representations of its input and output without using sequence-\n",
            "aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\n",
            "self-attention and discuss its advantages over models such as [17, 18] and [9].\n",
            "3\n",
            "Model Architecture\n",
            "Most competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\n",
            "Here, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\n",
            "\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hypothesis Questions"
      ],
      "metadata": {
        "id": "fcSmnz-dlxnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "functions = [{\n",
        "    \"name\":\"hypothetical_questions\",\n",
        "    \"description\":\"Generate hypothetical questions (mainly 3) for a particular chunk of text after splitting\",\n",
        "    \"parameters\":{\n",
        "        \"type\":\"object\",\n",
        "        \"properties\":{\n",
        "            \"questions\":{\n",
        "                \"type\":\"array\",\n",
        "                \"items\":{\n",
        "                    \"type\":\"string\",\n",
        "                },\n",
        "            },\n",
        "        },\n",
        "        \"required\":[\"questions\"],\n",
        "    }\n",
        "}]"
      ],
      "metadata": {
        "id": "AYbrKaM7qSHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "\n",
        "hypothetical_query_chain = (\n",
        "    {\"doc\":lambda x:x} |\n",
        "    ChatPromptTemplate.from_template('''\n",
        "    Act as an AI industry analyst.Based on the document below, generate exactly 3 sophisticated questions that a venture capitalist or product manager would ask to understand the document's implications.\n",
        "    Focus on market impact, technical differentiation, or scalability.\n",
        "    Document: {doc}\n",
        "    Output: Exactly 3 high-level questions in English.''') | ChatOpenAI(max_retries=0,model='gpt-4o-mini').bind(\n",
        "      functions=functions,function_call = {'name':'hypothetical_questions'}\n",
        "    ) | JsonOutputFunctionsParser(key_name = 'questions'))"
      ],
      "metadata": {
        "id": "KJfI8SSPoU2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = hypothetical_query_chain.invoke(texts[3])\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYNV097Sw_fe",
        "outputId": "d38fd301-16d7-4c65-8c30-4aeee976df1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'questions': ['How does the significantly reduced training cost of the Transformer model compared to traditional models influence its adoption in the market, particularly for startups and small organizations?',\n",
              "  \"In what ways does the Transformer model's ability to generalize across tasks, such as English constituency parsing with varying amounts of training data, create opportunities for new applications or products in NLP and beyond?\",\n",
              "  'Considering the technical innovations introduced by the Transformer model, including self-attention mechanisms and multi-head attention, how scalable is this architecture for future advancements in AI, particularly with larger datasets and more complex tasks?']}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypothetical_questions = hypothetical_query_chain.batch(texts,{'max_concurrency':10})"
      ],
      "metadata": {
        "id": "q09i0i_9xQbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypothetical_questions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "obB_3xxx6Flk",
        "outputId": "adafdcb0-4187-4f8c-e6e8-5687f3583d0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'questions': ['How does the introduction of attention mechanisms in sequence transduction models alter the competitive landscape for AI-driven applications in both commercial and academic settings?',\n",
              "   'In what ways can the technical advancements presented in this document be leveraged to drive scalability and efficiency in existing natural language processing solutions?',\n",
              "   'What potential market opportunities might arise from the adoption of the proposed models, and how can companies position themselves to capitalize on these innovations within the rapidly evolving AI ecosystem?']},\n",
              " {'questions': ['How does the introduction of the Transformer architecture affect the competitive landscape of existing sequence transduction models, particularly in terms of market adoption and potential disruptions?',\n",
              "   'In what ways does the reliance solely on attention mechanisms in the Transformer architecture present advantages or challenges in scalability compared to recurrent or convolutional neural networks?',\n",
              "   'What implications does the enhanced parallelizability of the Transformer model have for future developments in AI infrastructure and model deployment in high-demand environments?']},\n",
              " {'questions': ['How might the superior performance of this model in machine translation impact current market leaders in AI language processing?',\n",
              "   \"What technical innovations contribute to the model's efficient training time, and how can these be leveraged to create additional competitive advantages in various applications?\",\n",
              "   \"Given the model's scalability demonstrated through multi-GPU training, what are the potential implications for deployment in large-scale commercial applications?\"]},\n",
              " {'questions': ['What advantages does the training efficiency achieved in this study provide for potential adoption in large-scale enterprises or real-world applications?',\n",
              "   'How does the successful application of the Transformer model to English constituency parsing with varying data sizes position it against existing solutions in terms of market competitiveness and technical differentiation?',\n",
              "   \"In what ways can the scalability of the Transformer model's training process be leveraged for the development of future AI products, and what limitations should we be aware of?\"]},\n",
              " {'questions': ['How does the introduction of scaled dot-product attention and multi-head attention differentiate our models from competitors in the market?',\n",
              "   'What are the potential scalability challenges involved in maintaining and improving the tensor2tensor codebase as we expand our model variations?',\n",
              "   'In what ways do the recent improvements in our original codebase enhance the overall market impact of our research outputs compared to previous systems?']},\n",
              " {'questions': ['How does the implementation of tensor2tensor position the company within the competitive landscape of AI research and product development?',\n",
              "   'What specific technical differentiators does tensor2tensor offer that could lead to a significant advantage in our product offerings over competitors?',\n",
              "   'In what ways can the scalability of the tensor2tensor framework be leveraged to address larger market demands and enhance our research capabilities?']},\n",
              " {'questions': ['How do the advances in recurrent neural networks and encoder-decoder architectures affect the competitive landscape in AI-powered language processing applications?',\n",
              "   'What specific technical differentiators can be identified in the latest iterations of recurrent language models that justify investment, and how might they influence market adoption?',\n",
              "   'Considering scalability, what challenges might arise as organizations seek to implement and deploy advanced recurrent neural networks for large-scale language modeling tasks?']},\n",
              " {'questions': ['How might the improvements in computational efficiency through factorization tricks and conditional computation impact the overall market for sequential data processing models?',\n",
              "   'What technical differentiations can be leveraged from the advancements in recurrent model architectures to create a competitive advantage in the AI space?',\n",
              "   'In what ways can the scalability limitations posed by memory constraints in training recurrent models be addressed to facilitate larger batch processing and faster model training, potentially reshaping industry standards?']},\n",
              " {'questions': ['How could the introduction of the Transformer model architecture, which eliminates recurrence, disrupt existing market solutions that rely on recurrent networks?',\n",
              "   'What are the potential scalability challenges or benefits associated with implementing effective attention mechanisms in various applications, particularly in large-scale models?',\n",
              "   'In what ways do the improvements in computational efficiency through factorization tricks and conditional computation impact the competitive landscape for AI models targeting sequence modeling tasks?']},\n",
              " {'questions': [\"How does the Transformer model's reliance on an attention mechanism rather than recurrence impact its scalability compared to traditional recurrent neural networks in real-world applications?\",\n",
              "   'In what ways might the state-of-the-art performance of the Transformer model in translation quality influence market dynamics and competitiveness among existing AI translation services?',\n",
              "   'Considering the ability of the Transformer to leverage parallelization, what implications could this have for the cost structure and resource allocation of companies looking to implement this technology in production environments?']},\n",
              " {'questions': ['What competitive advantages do the parallel computation methods employed by models like the Transformer, ByteNet, and ConvS2S provide over traditional sequential models in terms of market adoption?',\n",
              "   'How might the varying operational complexities of these models (linear for ConvS2S and logarithmic for ByteNet) influence their scalability in real-world applications across different industries?',\n",
              "   'What implications do the challenges of learning dependencies between distant positions have on the development of future models, and how could addressing these challenges create new market opportunities?']},\n",
              " {'questions': [\"How does the technical differentiation of the Transformer model's attention mechanism position it against traditional sequence models like ConvS2S and ByteNet in terms of market adoption and scalability?\",\n",
              "   \"What are the implications of reduced effective resolution in the Transformer's attention mechanism for practical applications in natural language processing and how might this impact its competitive edge in the market?\",\n",
              "   'Can the advancements made in Multi-Head Attention enhance the performance of the Transformer model in large-scale systems, and what are the potential challenges for scalability as demand for processing complex sequences increases?']},\n",
              " {'questions': ['How does the self-attention mechanism in Transformers provide a competitive advantage over traditional recurrent models in various natural language processing tasks?',\n",
              "   'What are the scalability implications of adopting Transformer-based architectures for large-scale language tasks compared to end-to-end memory networks?',\n",
              "   'In what ways could the unique features of the Transformer architecture influence potential market applications in AI-driven solutions, particularly in reading comprehension and textual entailment?']},\n",
              " {'questions': ['How does the use of self-attention in the Transformer model provide a competitive edge over traditional RNN and convolution-based models in addressing language modeling tasks?',\n",
              "   'What are the potential market applications for the Transformer model, and how could its unique architecture influence the demand for AI-driven language processing solutions?',\n",
              "   'In what ways can the scalability of the Transformer model be leveraged to support larger datasets and more complex language tasks, and what implications does this have for future AI product development?']},\n",
              " {'questions': [\"How does the auto-regressive nature of the encoder-decoder structure influence the model's performance in real-time applications compared to non-auto-regressive models?\",\n",
              "   'In what ways can the continuous representations z be optimized to improve the efficiency and accuracy of the output sequences generated by the decoder, and what is the competitive advantage of these optimizations in the current market?',\n",
              "   'What potential scalability challenges might arise when applying this encoder-decoder structure to larger datasets or more complex sequences, and how can these challenges be addressed to ensure viability for enterprise-level solutions?']},\n",
              " {'questions': ['How does the self-attention mechanism in the Transformer architecture differentiate it from traditional neural networks, and what advantages does this differentiation bring to market applications?',\n",
              "   \"In what ways can the scalability of the Transformer model's architecture impact its adoption in real-world applications, especially in industries requiring large-scale data processing?\",\n",
              "   'What potential market opportunities could arise from the unique features of the Transformer model, considering its capabilities in natural language processing and other domains?']},\n",
              " {'questions': ['How does the implementation of residual connections and layer normalization in the fully connected feed-forward network enhance its performance compared to traditional models in terms of accuracy and convergence speed?',\n",
              "   'What competitive advantages could this architecture provide in scalability for real-time applications, and how might it position our offering against current solutions in the market?',\n",
              "   \"In what ways could the inclusion of the multi-head sub-layer in the decoder influence the model's ability to handle complex tasks, and what implications does this have for future product development and feature enhancements?\"]},\n",
              " {'questions': ['How does the unique architecture of the decoder, especially with its additional layer and masking strategy, differentiate it from other models in the market and what competitive advantage might this confer?',\n",
              "   'Considering the scalability of the model architecture described, what are the potential implications for processing larger datasets or real-time applications in production environments?',\n",
              "   'What market trends or user needs could this advanced decoder technology address, and how might it influence future product development in AI-driven applications?']},\n",
              " {'questions': ['How does the proposed attention mechanism differentiate itself from existing models in terms of computational efficiency and accuracy in predictions?',\n",
              "   'What potential markets could benefit from the introduction of this attention function, and how do we anticipate this will drive adoption and create competitive advantages?',\n",
              "   'In what ways can this attention mechanism be scaled to handle larger datasets or more complex queries, and what implications could that have for its implementation in real-world applications?']},\n",
              " {'questions': ['How does the use of Scaled Dot-Product Attention and Multi-Head Attention differentiate this approach from existing attention mechanisms in the AI market, and what competitive advantages could it provide?',\n",
              "   'In what ways can the implementation of these attention mechanisms be scaled across various industry applications, and what potential markets could benefit the most from this technology?',\n",
              "   'What are the implications of using a softmax function in the context of Scaled Dot-Product Attention for handling large datasets, and how might it impact performance and resource allocation in real-world scenarios?']},\n",
              " {'questions': ['How does the implementation of the softmax function in the attention mechanism differentiate this approach from traditional methods in terms of computational efficiency and scalability for large datasets?',\n",
              "   'In what ways could the adoption of this attention function lead to competitive advantages in market sectors that heavily rely on natural language processing or machine learning applications?',\n",
              "   'What potential challenges and limitations do you foresee in scaling this attention mechanism for real-time applications, particularly in dynamic environments where rapid data processing is crucial?']},\n",
              " {'questions': ['How does the trade-off between the speed and space efficiency of dot-product attention versus the performance of additive attention for larger values of dk affect market adoption in machine learning applications?',\n",
              "   'What unique advantages does the additive attention mechanism provide in terms of technical differentiation for AI products compared to existing alternatives, particularly in handling large datasets?',\n",
              "   'Given the scalability challenges identified with dot-product attention in high-dk scenarios, what potential market opportunities exist for developing specialized hardware or software solutions that optimize attention mechanisms in large-scale AI systems?']},\n",
              " {'questions': ['How does scaling the dot products in the softmax function influence the effectiveness of multi-head attention in large-scale AI models, and what competitive advantages might this offer in the market?',\n",
              "   'In what ways can the implementation of multi-head attention with learned linear projections enhance the performance of AI applications, and how can this differentiate products in a crowded marketplace?',\n",
              "   'Considering the scalability of these techniques in real-world applications, what challenges might arise as the size of the model increases, and how could they impact the overall adoption of this technology in various industries?']},\n",
              " {'questions': ['How does the parallel attention function described in the document impact the scalability of AI models in high-dimensional data environments?',\n",
              "   'What are the potential market implications of using independent random variables for queries and keys in attention mechanisms, particularly in terms of performance optimization in real-world applications?',\n",
              "   'In what ways does the mathematical foundation of dot products in attention mechanisms provide a technical differentiation that could potentially disrupt current AI technologies or frameworks?']},\n",
              " {'questions': ['How does the implementation of multi-head attention in this model differentiate it from existing models in the market?',\n",
              "   'What potential market applications could arise from the scalability of this multi-head attention technique, particularly in industries reliant on large datasets?',\n",
              "   \"How might the use of parallel attention layers influence the model's overall performance and its adoption by product teams in operational environments?\"]},\n",
              " {'questions': ['How does the implementation of multi-head attention with reduced dimensions impact the overall computational efficiency and performance in real-world applications?',\n",
              "   'What specific market problems does the proposed attention mechanism aim to solve, and how does it compare to existing solutions in terms of scalability and adaptability?',\n",
              "   \"In what ways can this model's architecture facilitate advancements in various industries, and how might it influence future product development strategies within those sectors?\"]},\n",
              " {'questions': ['How does the use of encoder-decoder attention layers in sequence-to-sequence models enhance the potential for market adoption of AI-driven applications in natural language processing?',\n",
              "   'What are the technical advantages of self-attention layers over traditional RNN architectures, and how could these advantages be leveraged to create a competitive differentiation in the AI marketplace?',\n",
              "   'In what ways can the scalability of the described attention mechanisms impact their applicability in handling large datasets across various industries, such as healthcare, finance, and customer service?']},\n",
              " {'questions': [\"How does the implementation of masked self-attention in the decoder enhance the model's performance compared to other architectures, particularly in terms of market application?\",\n",
              "   'In what ways can the position-wise feed-forward networks be optimized to improve their scalability in real-world applications, especially given the growing data demands in the AI industry?',\n",
              "   'What competitive advantages does this encoder-decoder structure have over traditional models in terms of technical differentiation and potential market impact?']},\n",
              " {'questions': ['How does the implementation of position-wise feed-forward networks contribute to the overall performance and efficiency of the model in handling large datasets?',\n",
              "   'What competitive advantages could arise from the technical differentiation provided by the use of shared parameters across positions in the feed-forward network?',\n",
              "   'In what ways can the scalability of this architecture be assessed, especially regarding its application in real-time processing or large-scale deployments?']},\n",
              " {'questions': [\"How might the use of distinct parameters across layers influence the model's performance in real-world applications, and what implications does this have for scaling the model to larger datasets?\",\n",
              "   'What technical advantages do the described linear transformations and learned embeddings provide compared to existing models in terms of market competitiveness and potential differentiation?',\n",
              "   \"In what ways does the architecture's specification of input and output dimensions (dmodel and dff) affect its scalability for applications requiring real-time processing and large-scale deployment?\"]},\n",
              " {'questions': ['How does the shared weight matrix architecture contribute to performance efficiency and what competitive advantage does it provide in the context of the current market landscape?',\n",
              "   'What are the scalability challenges associated with implementing a shared weight matrix approach in large-scale models, and how can these be effectively mitigated?',\n",
              "   \"In what ways does the use of the softmax function in predicting next-token probabilities enhance the model's differentiation from existing alternatives in the AI market?\"]},\n",
              " {'questions': ['How does the technical differentiation of the self-attention mechanism in the proposed model impact its performance and scalability compared to traditional recurrent and convolutional architectures?',\n",
              "   \"What implications does the reduced maximum path length and complexity per layer have on the model's market viability in real-time applications, particularly in comparison to existing models?\",\n",
              "   \"In what ways can the proposed model's reliance on self-attention contribute to its adaptability across various domains, and what market opportunities arise from its unique operational efficiencies?\"]},\n",
              " {'questions': ['How does the use of sine and cosine functions for positional encoding provide a technical advantage over traditional methods in handling sequential data?',\n",
              "   'What potential market opportunities arise from the scalability of this self-attention model, particularly in industries that rely heavily on sequence processing?',\n",
              "   'In what ways might the lack of recurrence and convolution in the architecture influence its competitive differentiation in the AI space, especially in comparison to existing models that utilize these mechanisms?']},\n",
              " {'questions': [\"How does the choice of sine and cosine functions for positional encoding impact the model's performance in different market applications?\",\n",
              "   'What are the technical advantages of using relative positional encodings over traditional fixed encodings, and how can this differentiation be leveraged in a competitive landscape?',\n",
              "   'In terms of scalability, how can the proposed approach to positional encoding be adapted to handle larger datasets or more complex neural network architectures?']},\n",
              " {'questions': ['What advantages do sinusoidal positional embeddings offer over learned embeddings in terms of model scalability and performance in different market applications?',\n",
              "   'How might the ability of self-attention mechanisms to handle variable-length sequences position our product against competitors using recurrent or convolutional layers?',\n",
              "   'In what ways could the findings on self-attention and positional embeddings influence the future development and deployment of AI models across various industries?']},\n",
              " {'questions': ['How does the scalability of self-attention mechanisms compare to recurrent and convolutional layers when applied to large-scale sequence transduction tasks?',\n",
              "   'In what ways does the computational complexity of self-attention layers influence their adoption in commercial applications versus traditional architectures?',\n",
              "   'What technical differentiators of self-attention layers position them as a preferred solution in the evolving landscape of AI-driven language models and other sequence-based tasks?']},\n",
              " {'questions': ['How does the computational complexity per layer influence the overall performance and efficiency of the model in practical applications?',\n",
              "   'What advantages does the ability to parallelize computations offer in terms of scalability when deploying this technology across different platforms or in high-demand scenarios?',\n",
              "   'In what ways could optimizing the path length for learning long-range dependencies impact the competitive landscape of models designed for sequence transduction tasks?']},\n",
              " {'questions': ['How could the scalability of self-attention layers over recurrent layers influence our market positioning against competitors who rely on traditional recurrent neural networks?',\n",
              "   'What strategic partnerships or investments might be needed to capitalize on the potential performance advantages of self-attention mechanisms in various applications?',\n",
              "   'In what ways does the demonstrated efficiency of self-attention layers impact our cost structure, particularly in relation to training large models for production use?']},\n",
              " {'questions': ['How could limiting self-attention to a local neighborhood size r impact the performance and accuracy of state-of-the-art models in machine translation in longer sequences?',\n",
              "   'What competitive advantages could be achieved by implementing the proposed approach of restricting self-attention, and how might this differentiate our offering in a rapidly evolving AI landscape?',\n",
              "   'Considering the scalability of this method, how might adjusting the neighborhood size r influence resource allocation and computational efficiency as we expand into larger datasets or more complex language tasks?']},\n",
              " {'questions': ['How does the proposed path length of O(n/r) impact the overall performance and efficiency of convolutional networks compared to current leading architectures?',\n",
              "   'What specific technical differentiators set apart this approach from existing convolution methods, and how do they influence scalability in large-scale applications?',\n",
              "   'In light of the potential increase in network complexity due to the O(n/k) and O(logk(n)) stack requirements, what strategies can be employed to maintain cost-effectiveness and competitive advantage in the market?']},\n",
              " {'questions': ['How does the introduction of separable convolutions and self-attention layers position our model against competitors in the current AI market landscape?',\n",
              "   'What are the scalability implications of using self-attention in our model, particularly in handling large datasets or real-time processing applications?',\n",
              "   'In what ways can the interpretability of our self-attention mechanisms be leveraged to enhance user trust or facilitate better integration with existing systems in targeted industries?']},\n",
              " {'questions': ['How does the demonstrated capability of models to learn different tasks based on syntactic and semantic structures influence their potential applications in various industries, and what specific market segments could be targeted for maximum impact?',\n",
              "   'What technical differentiators in the training methodology, such as the implementation of byte-pair encoding and the choice of datasets (WMT 2014 English-German and English-French), could provide a competitive advantage in the NLP space?',\n",
              "   'Given the significant scalability of the models due to the size of the training datasets, how can we leverage this scalability to accommodate real-time language processing demands in applications like translation services or conversational AI?']},\n",
              " {'questions': ['How does the use of the WMT 2014 English-French dataset influence the competitive edge of the product in the translation market?',\n",
              "   'What are the scalability implications of utilizing a single machine with 8 NVIDIA P100 GPUs for model training, and how might this affect future growth opportunities?',\n",
              "   'In what ways could the technical differentiation provided by a unique vocabulary and batching strategy impact user adoption and retention in multilingual applications?']},\n",
              " {'questions': ['How does the choice of hardware and training duration impact the competitive landscape for similar AI models in the industry?',\n",
              "   'What are the potential scalability challenges associated with increasing model size and training steps as outlined in the document?',\n",
              "   'In what ways does the Adam optimizer configuration contribute to technical differentiation compared to other optimization strategies in AI model training?']},\n",
              " {'questions': [\"How does the proposed learning rate adjustment mechanism enhance the model's performance compared to traditional methods, and what market advantage does this offer?\",\n",
              "   'What scalability challenges might arise from implementing the described regularization techniques in more extensive training regimes or with larger datasets?',\n",
              "   'In what ways can the combination of warmup steps and inverse square root decay be differentiated from existing state-of-the-art training strategies, and how might this differentiation influence investment opportunities?']},\n",
              " {'questions': ['How does the cost-effectiveness of the Transformer model compare to its competitors influence its potential adoption by businesses in translation technology?',\n",
              "   \"What underlying technical differentiators in the Transformer's architecture contribute to its superior BLEU scores, and how can these be leveraged for future product enhancements?\",\n",
              "   'Considering the training cost advantages of the Transformer model, what scalability opportunities exist for deploying it in real-world applications beyond language translation?']},\n",
              " {'questions': ['How does the technical differentiation of the GNMT + RL ensemble compared to conventional models like Transformer impact its market adoption and potential for scalability?',\n",
              "   \"What specific features of the model's dropout and label smoothing techniques contribute to its performance metrics, and how might these influence the competitive landscape in AI solutions?\",\n",
              "   'Considering the output performance metrics presented, what are the implications for product development timelines and investment opportunities in achieving higher accuracy in natural language processing tasks?']},\n",
              " {'questions': ['What are the potential market applications for machine translation models leveraging label smoothing techniques, and how might these impact current industry standards?',\n",
              "   'How does the technical differentiation offered by the big transformer model in this document position it against competitors in the machine translation space, particularly regarding BLEU scores?',\n",
              "   'Considering the computational resources required for training these models, what scalability challenges might arise when deploying them in real-world applications, and how can they be addressed?']},\n",
              " {'questions': ['What are the potential market applications and commercial viability of implementing this new state-of-the-art BLEU score model in real-world translation services?',\n",
              "   'How does the reduction in training cost and the improved performance of this model position it against existing competitors in the AI translation market?',\n",
              "   \"What are the technical implications of the model's architecture and training configuration that contribute to its scalability for other language pairs beyond English-to-French?\"]},\n",
              " {'questions': ['What potential competitive advantages does the dropout rate adjustment from 0.3 to 0.1 offer in terms of training efficiency and final model performance, particularly within the market of language translation models?',\n",
              "   \"How does the use of checkpoint averaging and specific hyperparameters such as beam size and length penalty influence the model's scalability and its ability to adapt to other languages or translation tasks?\",\n",
              "   'In what ways do the reported translation quality and training costs compare to emerging alternatives in the market, and how might this affect investment decisions in AI-driven translation technologies?']},\n",
              " {'questions': [\"How does the proposed model's approach to optimizing input length influence its competitive position in the translation market, especially against established players?\",\n",
              "   'What technical differentiators does this model present compared to existing architectures, and how might these affect its adoption in commercial applications?',\n",
              "   'Considering the training costs outlined in the document, how scalable is this model for large-scale deployment in enterprise applications, and what implications does this have for investment opportunities?']},\n",
              " {'questions': ['How do the performance variations of the Transformer components affect the competitive landscape in machine translation technologies?',\n",
              "   'What specific technical differentiations can be leveraged to improve scalability and efficiency in high-performance computing environments for translation tasks?',\n",
              "   'In what ways can the insights gained from this evaluation guide product development strategies for AI-driven translation services in international markets?']},\n",
              " {'questions': ['What are the potential market implications of the performance variations observed in different Transformer architectures, particularly in the context of English-to-German translation applications?',\n",
              "   'How does the technical differentiation presented in the varied configurations of hyperparameters indicate the scalability of these Transformer models in real-world applications, and what challenges may arise in deploying these models at scale?',\n",
              "   'In what ways can the findings related to perplexities and BLEU scores inform product managers about consumer preferences and expectations for translation services, and how might this data impact competitive positioning within the AI language translation market?']},\n",
              " {'questions': ['What strategies could be employed to leverage the technical differentiation offered by positional embedding over sinusoidal methods in developing scalable AI models?',\n",
              "   'How do the performance metrics presented in this document correlate with market trends in AI, specifically regarding the adoption of advanced attention mechanisms?',\n",
              "   'What implications do the variations in attention heads and key/value dimensions have on the potential scalability and market competitiveness of products utilizing this research?']},\n",
              " {'questions': ['How could the findings on attention head configurations influence the design of next-generation natural language processing models and their market adoption?',\n",
              "   'What are the technical implications of the suggested need for a more sophisticated compatibility function beyond dot product in terms of scalability and performance enhancement?',\n",
              "   'In what ways could the observed trade-offs in model quality with varying attention parameters affect competitive positioning in the AI language model market?']},\n",
              " {'questions': ['How will the proposed sophisticated compatibility function improve market adoption compared to existing solutions in natural language processing?',\n",
              "   'What technical advantages do learned positional embeddings provide over sinusoidal positional encodings in terms of model performance and scalability for future AI applications?',\n",
              "   'Given the observation that larger models yield better results, what strategies can be implemented to ensure efficient scaling while managing resource constraints in production environments?']},\n",
              " {'questions': ['How does the application of transformer models in constituency parsing present a competitive advantage over traditional RNN models, particularly in terms of handling small data sets?',\n",
              "   'What implications do the semi-supervised training techniques have on the scalability and efficiency of constituency parsing solutions in real-world applications?',\n",
              "   'Given the significant increase in vocabulary size in different training settings, how might this impact the marketability of products leveraging this technology to cater to diverse linguistic data?']},\n",
              " {'questions': ['How does the choice of vocabulary size impact the overall performance and market adoption of translation models in multilingual applications?',\n",
              "   'In what ways does the use of larger corpora, such as the high-confidence and BerkleyParser datasets, differentiate this model from existing solutions, and how could this affect its competitive positioning?',\n",
              "   'Considering the limited number of experiments conducted for parameter selection, what are the scalability implications of this approach when implementing the model across different languages with varying complexities?']},\n",
              " {'questions': ['How does the performance of the Transformer architecture in English constituency parsing compare to traditional discriminative models, and what does this indicate about its potential market applicability in natural language processing applications?',\n",
              "   'What are the key technical differentiators of the Transformer model that enable it to achieve competitive or superior parsing accuracy compared to other established models, and how might these advantages be leveraged for scalability in other linguistic tasks?',\n",
              "   \"Considering the Transformer model's performance across different training methodologies (discriminative, semi-supervised, multi-task), what implications does this have for the future development of parsing technologies and their integration into commercial platforms?\"]},\n",
              " {'questions': ['What implications do the advancements in semi-supervised learning, as highlighted in the document, have for the market adoption of machine learning technologies across various industries?',\n",
              "   'How does the technical differentiation presented in the results, particularly the performance of the Transformer model at a 92.7 accuracy, position this solution against traditional RNNs in terms of scalability and deployment in real-world applications?',\n",
              "   'What are the potential scalability challenges and solutions that could arise from increasing the maximum output length in generative models, and how might these challenges impact future product development in AI-driven applications?']},\n",
              " {'questions': ['How does the introduction of the Transformer model impact the competitive landscape for natural language processing applications, particularly in translation tasks?',\n",
              "   'What specific technical advantages does the Transformer model offer over traditional RNN architectures that could lead to superior performance and faster training times?',\n",
              "   'In what ways can the scalability of the Transformer model be leveraged to capture emerging market opportunities in AI-driven language services and applications?']},\n",
              " {'questions': ['What potential market applications can be identified for multi-headed self-attention beyond language translation, and how might they disrupt existing industries?',\n",
              "   'In what ways does the technical differentiation of the Transformer model compare to traditional architectures, and what are the implications for scaling its deployment in real-world applications?',\n",
              "   'What challenges might arise in extending the Transformer to non-textual modalities, and how could the efficiency of local attention mechanisms influence its scalability across different use cases?']},\n",
              " {'questions': ['How might the development of local, restricted attention mechanisms influence competitive positioning in the market for AI-generated content across different modalities like images, audio, and video?',\n",
              "   'What unique technical advantages could our approach to less sequential generation provide in comparison to existing models, and how could this enhance scalability in real-world applications?',\n",
              "   'Given the emphasis on handling large inputs and outputs efficiently, what potential limitations exist for scaling up this technology in diverse industries, and how can we address them?']},\n",
              " {'questions': ['What are the potential market applications of the neural machine translation (NMT) advancements discussed, and how might they disrupt current translation services?',\n",
              "   'In what ways do the technical differentiations mentioned in the document enhance the efficiency or accuracy of neural machine translation compared to traditional methods?',\n",
              "   'How scalable are the proposed NMT architectures in handling large datasets across diverse languages, and what implications does this have for global communication and business?']},\n",
              " {'questions': ['How do the techniques and models discussed in these papers differentiate from existing solutions in the field of machine translation and sequence modeling, particularly in terms of performance and computational efficiency?',\n",
              "   'What market trends or demands could these advances in deep learning and recurrent neural networks address, and how might they influence the competitive landscape for AI-driven language processing applications?',\n",
              "   'Considering the scalability of the proposed models, what are the potential challenges and takeaways for organizations looking to implement these advanced neural network architectures in real-world applications?']},\n",
              " {'questions': ['What are the potential market applications of recurrent and convolutional neural network approaches discussed in these studies, and how could they disrupt current solutions in natural language processing and image recognition?',\n",
              "   'How do the architectural innovations in recurrent and convolutional networks, as highlighted in these papers, provide a competitive advantage over existing technologies in terms of performance and scalability?',\n",
              "   'In what ways can the findings from these studies inform future product development, and what considerations should be made regarding the integration of these advanced neural network models into existing systems?']},\n",
              " {'questions': ['What potential markets could be disrupted by advancements in age recognition technology, and how can this be leveraged for product innovation?',\n",
              "   'How does the integration of techniques from long short-term memory networks enhance the accuracy and reliability of age recognition systems compared to traditional methods?',\n",
              "   'What strategies can be employed to scale age recognition technology across diverse applications while maintaining performance across varying demographic variables?']},\n",
              " {'questions': ['How could advancements in language modeling techniques influence the competitiveness of AI-driven applications across different industries?',\n",
              "   'What are the potential scalability challenges associated with implementing active memory systems in real-world natural language processing applications?',\n",
              "   'In what ways do the technical differentiations highlighted in the explored algorithms influence the ability to integrate these models into existing software ecosystems?']},\n",
              " {'questions': ['What market opportunities could arise from advancements in neural machine translation as presented in the document, and how might these shape competitive dynamics in the AI sector?',\n",
              "   'How does the proposed linear time neural machine translation approach technically differentiate itself from traditional models, and what implications does this have for performance and user experience?',\n",
              "   'In what ways can the scalability of the methodologies discussed in the document be leveraged to meet the growing demands for translation services in diverse industries, and what challenges might arise in implementing these solutions at scale?']},\n",
              " {'questions': ['How might the advancements in structured self-attentive sentence embeddings impact the competitive landscape of natural language processing applications?',\n",
              "   'In what ways do the methodologies outlined in the document differentiate themselves technically from existing models in sequence-to-sequence learning?',\n",
              "   'What are the scalability implications of the multi-task sequence learning approach presented in the document, especially in the context of evolving business requirements and data volume?']},\n",
              " {'questions': [\"How does the Penn Treebank's annotated corpus influence current natural language processing models, and what implications does this have for market trends in NLP technologies?\",\n",
              "   'In what ways do the advancements in self-training parsing techniques from McClosky et al. provide a competitive edge for scaling NLP applications across diverse industries?',\n",
              "   'Considering the differentiated approaches in attention models as shown by Parikh et al. and Paulus et al., how can these innovations be leveraged to create scalable and marketable AI products in the future?']},\n",
              " {'questions': ['What market opportunities arise from advancements in deep reinforced models for abstractive summarization as discussed in the document?',\n",
              "   'How do the technical differentiators presented in the research, such as improved language models and tree annotation, enhance product offerings in the NLP space?',\n",
              "   'In what ways can the methodologies outlined in the document scale to meet the growing demand for efficient and interpretable natural language processing solutions?']},\n",
              " {'questions': ['How do the advancements in language modeling techniques presented in these studies influence the competitive landscape for AI-driven language applications, and what opportunities may arise for new market entrants?',\n",
              "   'What technical differentiators do the proposed methods, particularly those involving neural machine translation and large neural networks, present that could redefine performance benchmarks in natural language processing?',\n",
              "   'Given the findings on model scalability and language understanding, what implications do these advances have for the deployment of AI technologies in real-world applications across various industries, and how might they impact user experiences?']},\n",
              " {'questions': ['How could the advancements in dropout techniques as discussed in Srivastava et al. (2014) influence market trends in artificial intelligence by improving model performance and reducing training costs?',\n",
              "   'In what ways do end-to-end memory networks introduced by Sukhbaatar et al. (2015) provide a technical differentiation that could be leveraged to create competitive advantages in memory-intensive AI applications?',\n",
              "   'Considering the sequence-to-sequence learning framework presented by Sutskever et al. (2014), how scalable are these models in real-world applications, and what factors could limit their adoption in industry-specific use cases?']},\n",
              " {'questions': ['How do the advancements in neural architectures discussed in the document differentiate them from traditional models, and what implications does this have for competitive positioning in the market?',\n",
              "   'What scalability challenges might arise from implementing the sequence-to-sequence learning strategies outlined in the document, and how could these challenges affect potential adoption by commercial enterprises?',\n",
              "   'Given the evolution of computer vision techniques highlighted in the research, what are the potential impacts on existing applications and industries, and how might this influence future investment opportunities in AI-driven sectors?']},\n",
              " {'questions': ['How do the advancements in neural machine translation algorithms discussed in this document distinguish themselves from previous approaches, and what implications does this have for existing market players?',\n",
              "   'What are the scalability challenges and opportunities presented by the deep recurrent models with fast-forward connections for neural machine translation, and how might these influence future product development in the field?',\n",
              "   'In what ways do the findings related to constituent parsing in this document suggest potential shifts in the competitive landscape of natural language processing technologies, particularly concerning the integration of machine translation systems?']},\n",
              " {'questions': ['What competitive advantages does the proposed shift-reduce constituent parsing technique offer over existing parsing methods in terms of accuracy and processing speed?',\n",
              "   'How does this research align with the current trends in natural language processing, and what potential market applications could arise from its implementation?',\n",
              "   'What challenges could emerge in scaling this parsing technique for real-world applications, particularly in diverse language contexts or large-scale datasets?']},\n",
              " {'questions': ['How might the recent changes in voting laws impact the adoption and development of AI technologies aimed at improving civic engagement and voter participation?',\n",
              "   'What technical differentiators do existing AI models possess that can effectively address the complexities introduced by the new voting laws, particularly in areas of data visualization and user experience?',\n",
              "   'In what ways can AI-driven solutions scale to assist diverse groups of voters while navigating the challenges presented by stricter registration processes, and what market opportunities does this create for product innovation?']},\n",
              " {'questions': ['How could the insights gained from the attention mechanism in the encoder self-attention impact future AI model architectures and their performance on long-distance dependencies?',\n",
              "   'What advantages does the use of multiple attention heads bring in the context of natural language processing, and how might this differentiation position the product in a competitive market?',\n",
              "   'In terms of scalability, how can this attention mechanism be optimized for larger datasets or more complex models, and what implications does this have for deployment in real-world applications?']},\n",
              " {'questions': ['How can the application of law be optimized to ensure fairness and equity in various sectors, and what technologies could facilitate this improvement?',\n",
              "   'What kind of competitive advantages can emerge from successfully addressing the inadequacies in legal applications as highlighted in the document?',\n",
              "   'In what ways can scalability be achieved in legal frameworks to accommodate diverse jurisdictions while maintaining a just application of the law?']},\n",
              " {'questions': ['How does the differentiation of attention heads in layer 5 contribute to the overall performance and applicability of the model in real-world scenarios?',\n",
              "   'What specific market needs does the capability of anaphora resolution address, and how might this influence the competitive landscape within the AI sector?',\n",
              "   'In what ways can the technology leveraging these attention mechanisms be scaled across different industries or applications to maximize its impact?']},\n",
              " {'questions': ['What are the potential market advantages of prioritizing the equitable application of the law in technological solutions, and how can these be leveraged for competitive differentiation?',\n",
              "   'In what ways can advancements in the application of law enhance scalability for businesses operating in regulated industries, and what specific technologies could facilitate this growth?',\n",
              "   'How might the imperfections in the legal framework impact the development of AI-driven products, and what strategies can be employed to navigate these challenges effectively?']},\n",
              " {'questions': ['How do the findings regarding attention head behavior translate into a competitive advantage in AI model performance and application?',\n",
              "   'What potential markets could this technological differentiation unlock, particularly in relation to natural language processing tasks?',\n",
              "   'How scalable is the architecture discussed in the document, and what implications does this have for deploying these models in real-world applications?']}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypothetical_questions_list = []\n",
        "for i in hypothetical_questions:\n",
        "  hypothetical_questions_list.append(i['questions'])"
      ],
      "metadata": {
        "id": "eB8TcwGR7cSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypothetical_questions_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-xJ8r4DT7pv6",
        "outputId": "2d73177b-29b9-485b-a1dd-fd79c8c91b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['How does the introduction of attention mechanisms in sequence transduction models alter the competitive landscape for AI-driven applications in both commercial and academic settings?',\n",
              "  'In what ways can the technical advancements presented in this document be leveraged to drive scalability and efficiency in existing natural language processing solutions?',\n",
              "  'What potential market opportunities might arise from the adoption of the proposed models, and how can companies position themselves to capitalize on these innovations within the rapidly evolving AI ecosystem?'],\n",
              " ['How does the introduction of the Transformer architecture affect the competitive landscape of existing sequence transduction models, particularly in terms of market adoption and potential disruptions?',\n",
              "  'In what ways does the reliance solely on attention mechanisms in the Transformer architecture present advantages or challenges in scalability compared to recurrent or convolutional neural networks?',\n",
              "  'What implications does the enhanced parallelizability of the Transformer model have for future developments in AI infrastructure and model deployment in high-demand environments?'],\n",
              " ['How might the superior performance of this model in machine translation impact current market leaders in AI language processing?',\n",
              "  \"What technical innovations contribute to the model's efficient training time, and how can these be leveraged to create additional competitive advantages in various applications?\",\n",
              "  \"Given the model's scalability demonstrated through multi-GPU training, what are the potential implications for deployment in large-scale commercial applications?\"],\n",
              " ['What advantages does the training efficiency achieved in this study provide for potential adoption in large-scale enterprises or real-world applications?',\n",
              "  'How does the successful application of the Transformer model to English constituency parsing with varying data sizes position it against existing solutions in terms of market competitiveness and technical differentiation?',\n",
              "  \"In what ways can the scalability of the Transformer model's training process be leveraged for the development of future AI products, and what limitations should we be aware of?\"],\n",
              " ['How does the introduction of scaled dot-product attention and multi-head attention differentiate our models from competitors in the market?',\n",
              "  'What are the potential scalability challenges involved in maintaining and improving the tensor2tensor codebase as we expand our model variations?',\n",
              "  'In what ways do the recent improvements in our original codebase enhance the overall market impact of our research outputs compared to previous systems?'],\n",
              " ['How does the implementation of tensor2tensor position the company within the competitive landscape of AI research and product development?',\n",
              "  'What specific technical differentiators does tensor2tensor offer that could lead to a significant advantage in our product offerings over competitors?',\n",
              "  'In what ways can the scalability of the tensor2tensor framework be leveraged to address larger market demands and enhance our research capabilities?'],\n",
              " ['How do the advances in recurrent neural networks and encoder-decoder architectures affect the competitive landscape in AI-powered language processing applications?',\n",
              "  'What specific technical differentiators can be identified in the latest iterations of recurrent language models that justify investment, and how might they influence market adoption?',\n",
              "  'Considering scalability, what challenges might arise as organizations seek to implement and deploy advanced recurrent neural networks for large-scale language modeling tasks?'],\n",
              " ['How might the improvements in computational efficiency through factorization tricks and conditional computation impact the overall market for sequential data processing models?',\n",
              "  'What technical differentiations can be leveraged from the advancements in recurrent model architectures to create a competitive advantage in the AI space?',\n",
              "  'In what ways can the scalability limitations posed by memory constraints in training recurrent models be addressed to facilitate larger batch processing and faster model training, potentially reshaping industry standards?'],\n",
              " ['How could the introduction of the Transformer model architecture, which eliminates recurrence, disrupt existing market solutions that rely on recurrent networks?',\n",
              "  'What are the potential scalability challenges or benefits associated with implementing effective attention mechanisms in various applications, particularly in large-scale models?',\n",
              "  'In what ways do the improvements in computational efficiency through factorization tricks and conditional computation impact the competitive landscape for AI models targeting sequence modeling tasks?'],\n",
              " [\"How does the Transformer model's reliance on an attention mechanism rather than recurrence impact its scalability compared to traditional recurrent neural networks in real-world applications?\",\n",
              "  'In what ways might the state-of-the-art performance of the Transformer model in translation quality influence market dynamics and competitiveness among existing AI translation services?',\n",
              "  'Considering the ability of the Transformer to leverage parallelization, what implications could this have for the cost structure and resource allocation of companies looking to implement this technology in production environments?'],\n",
              " ['What competitive advantages do the parallel computation methods employed by models like the Transformer, ByteNet, and ConvS2S provide over traditional sequential models in terms of market adoption?',\n",
              "  'How might the varying operational complexities of these models (linear for ConvS2S and logarithmic for ByteNet) influence their scalability in real-world applications across different industries?',\n",
              "  'What implications do the challenges of learning dependencies between distant positions have on the development of future models, and how could addressing these challenges create new market opportunities?'],\n",
              " [\"How does the technical differentiation of the Transformer model's attention mechanism position it against traditional sequence models like ConvS2S and ByteNet in terms of market adoption and scalability?\",\n",
              "  \"What are the implications of reduced effective resolution in the Transformer's attention mechanism for practical applications in natural language processing and how might this impact its competitive edge in the market?\",\n",
              "  'Can the advancements made in Multi-Head Attention enhance the performance of the Transformer model in large-scale systems, and what are the potential challenges for scalability as demand for processing complex sequences increases?'],\n",
              " ['How does the self-attention mechanism in Transformers provide a competitive advantage over traditional recurrent models in various natural language processing tasks?',\n",
              "  'What are the scalability implications of adopting Transformer-based architectures for large-scale language tasks compared to end-to-end memory networks?',\n",
              "  'In what ways could the unique features of the Transformer architecture influence potential market applications in AI-driven solutions, particularly in reading comprehension and textual entailment?'],\n",
              " ['How does the use of self-attention in the Transformer model provide a competitive edge over traditional RNN and convolution-based models in addressing language modeling tasks?',\n",
              "  'What are the potential market applications for the Transformer model, and how could its unique architecture influence the demand for AI-driven language processing solutions?',\n",
              "  'In what ways can the scalability of the Transformer model be leveraged to support larger datasets and more complex language tasks, and what implications does this have for future AI product development?'],\n",
              " [\"How does the auto-regressive nature of the encoder-decoder structure influence the model's performance in real-time applications compared to non-auto-regressive models?\",\n",
              "  'In what ways can the continuous representations z be optimized to improve the efficiency and accuracy of the output sequences generated by the decoder, and what is the competitive advantage of these optimizations in the current market?',\n",
              "  'What potential scalability challenges might arise when applying this encoder-decoder structure to larger datasets or more complex sequences, and how can these challenges be addressed to ensure viability for enterprise-level solutions?'],\n",
              " ['How does the self-attention mechanism in the Transformer architecture differentiate it from traditional neural networks, and what advantages does this differentiation bring to market applications?',\n",
              "  \"In what ways can the scalability of the Transformer model's architecture impact its adoption in real-world applications, especially in industries requiring large-scale data processing?\",\n",
              "  'What potential market opportunities could arise from the unique features of the Transformer model, considering its capabilities in natural language processing and other domains?'],\n",
              " ['How does the implementation of residual connections and layer normalization in the fully connected feed-forward network enhance its performance compared to traditional models in terms of accuracy and convergence speed?',\n",
              "  'What competitive advantages could this architecture provide in scalability for real-time applications, and how might it position our offering against current solutions in the market?',\n",
              "  \"In what ways could the inclusion of the multi-head sub-layer in the decoder influence the model's ability to handle complex tasks, and what implications does this have for future product development and feature enhancements?\"],\n",
              " ['How does the unique architecture of the decoder, especially with its additional layer and masking strategy, differentiate it from other models in the market and what competitive advantage might this confer?',\n",
              "  'Considering the scalability of the model architecture described, what are the potential implications for processing larger datasets or real-time applications in production environments?',\n",
              "  'What market trends or user needs could this advanced decoder technology address, and how might it influence future product development in AI-driven applications?'],\n",
              " ['How does the proposed attention mechanism differentiate itself from existing models in terms of computational efficiency and accuracy in predictions?',\n",
              "  'What potential markets could benefit from the introduction of this attention function, and how do we anticipate this will drive adoption and create competitive advantages?',\n",
              "  'In what ways can this attention mechanism be scaled to handle larger datasets or more complex queries, and what implications could that have for its implementation in real-world applications?'],\n",
              " ['How does the use of Scaled Dot-Product Attention and Multi-Head Attention differentiate this approach from existing attention mechanisms in the AI market, and what competitive advantages could it provide?',\n",
              "  'In what ways can the implementation of these attention mechanisms be scaled across various industry applications, and what potential markets could benefit the most from this technology?',\n",
              "  'What are the implications of using a softmax function in the context of Scaled Dot-Product Attention for handling large datasets, and how might it impact performance and resource allocation in real-world scenarios?'],\n",
              " ['How does the implementation of the softmax function in the attention mechanism differentiate this approach from traditional methods in terms of computational efficiency and scalability for large datasets?',\n",
              "  'In what ways could the adoption of this attention function lead to competitive advantages in market sectors that heavily rely on natural language processing or machine learning applications?',\n",
              "  'What potential challenges and limitations do you foresee in scaling this attention mechanism for real-time applications, particularly in dynamic environments where rapid data processing is crucial?'],\n",
              " ['How does the trade-off between the speed and space efficiency of dot-product attention versus the performance of additive attention for larger values of dk affect market adoption in machine learning applications?',\n",
              "  'What unique advantages does the additive attention mechanism provide in terms of technical differentiation for AI products compared to existing alternatives, particularly in handling large datasets?',\n",
              "  'Given the scalability challenges identified with dot-product attention in high-dk scenarios, what potential market opportunities exist for developing specialized hardware or software solutions that optimize attention mechanisms in large-scale AI systems?'],\n",
              " ['How does scaling the dot products in the softmax function influence the effectiveness of multi-head attention in large-scale AI models, and what competitive advantages might this offer in the market?',\n",
              "  'In what ways can the implementation of multi-head attention with learned linear projections enhance the performance of AI applications, and how can this differentiate products in a crowded marketplace?',\n",
              "  'Considering the scalability of these techniques in real-world applications, what challenges might arise as the size of the model increases, and how could they impact the overall adoption of this technology in various industries?'],\n",
              " ['How does the parallel attention function described in the document impact the scalability of AI models in high-dimensional data environments?',\n",
              "  'What are the potential market implications of using independent random variables for queries and keys in attention mechanisms, particularly in terms of performance optimization in real-world applications?',\n",
              "  'In what ways does the mathematical foundation of dot products in attention mechanisms provide a technical differentiation that could potentially disrupt current AI technologies or frameworks?'],\n",
              " ['How does the implementation of multi-head attention in this model differentiate it from existing models in the market?',\n",
              "  'What potential market applications could arise from the scalability of this multi-head attention technique, particularly in industries reliant on large datasets?',\n",
              "  \"How might the use of parallel attention layers influence the model's overall performance and its adoption by product teams in operational environments?\"],\n",
              " ['How does the implementation of multi-head attention with reduced dimensions impact the overall computational efficiency and performance in real-world applications?',\n",
              "  'What specific market problems does the proposed attention mechanism aim to solve, and how does it compare to existing solutions in terms of scalability and adaptability?',\n",
              "  \"In what ways can this model's architecture facilitate advancements in various industries, and how might it influence future product development strategies within those sectors?\"],\n",
              " ['How does the use of encoder-decoder attention layers in sequence-to-sequence models enhance the potential for market adoption of AI-driven applications in natural language processing?',\n",
              "  'What are the technical advantages of self-attention layers over traditional RNN architectures, and how could these advantages be leveraged to create a competitive differentiation in the AI marketplace?',\n",
              "  'In what ways can the scalability of the described attention mechanisms impact their applicability in handling large datasets across various industries, such as healthcare, finance, and customer service?'],\n",
              " [\"How does the implementation of masked self-attention in the decoder enhance the model's performance compared to other architectures, particularly in terms of market application?\",\n",
              "  'In what ways can the position-wise feed-forward networks be optimized to improve their scalability in real-world applications, especially given the growing data demands in the AI industry?',\n",
              "  'What competitive advantages does this encoder-decoder structure have over traditional models in terms of technical differentiation and potential market impact?'],\n",
              " ['How does the implementation of position-wise feed-forward networks contribute to the overall performance and efficiency of the model in handling large datasets?',\n",
              "  'What competitive advantages could arise from the technical differentiation provided by the use of shared parameters across positions in the feed-forward network?',\n",
              "  'In what ways can the scalability of this architecture be assessed, especially regarding its application in real-time processing or large-scale deployments?'],\n",
              " [\"How might the use of distinct parameters across layers influence the model's performance in real-world applications, and what implications does this have for scaling the model to larger datasets?\",\n",
              "  'What technical advantages do the described linear transformations and learned embeddings provide compared to existing models in terms of market competitiveness and potential differentiation?',\n",
              "  \"In what ways does the architecture's specification of input and output dimensions (dmodel and dff) affect its scalability for applications requiring real-time processing and large-scale deployment?\"],\n",
              " ['How does the shared weight matrix architecture contribute to performance efficiency and what competitive advantage does it provide in the context of the current market landscape?',\n",
              "  'What are the scalability challenges associated with implementing a shared weight matrix approach in large-scale models, and how can these be effectively mitigated?',\n",
              "  \"In what ways does the use of the softmax function in predicting next-token probabilities enhance the model's differentiation from existing alternatives in the AI market?\"],\n",
              " ['How does the technical differentiation of the self-attention mechanism in the proposed model impact its performance and scalability compared to traditional recurrent and convolutional architectures?',\n",
              "  \"What implications does the reduced maximum path length and complexity per layer have on the model's market viability in real-time applications, particularly in comparison to existing models?\",\n",
              "  \"In what ways can the proposed model's reliance on self-attention contribute to its adaptability across various domains, and what market opportunities arise from its unique operational efficiencies?\"],\n",
              " ['How does the use of sine and cosine functions for positional encoding provide a technical advantage over traditional methods in handling sequential data?',\n",
              "  'What potential market opportunities arise from the scalability of this self-attention model, particularly in industries that rely heavily on sequence processing?',\n",
              "  'In what ways might the lack of recurrence and convolution in the architecture influence its competitive differentiation in the AI space, especially in comparison to existing models that utilize these mechanisms?'],\n",
              " [\"How does the choice of sine and cosine functions for positional encoding impact the model's performance in different market applications?\",\n",
              "  'What are the technical advantages of using relative positional encodings over traditional fixed encodings, and how can this differentiation be leveraged in a competitive landscape?',\n",
              "  'In terms of scalability, how can the proposed approach to positional encoding be adapted to handle larger datasets or more complex neural network architectures?'],\n",
              " ['What advantages do sinusoidal positional embeddings offer over learned embeddings in terms of model scalability and performance in different market applications?',\n",
              "  'How might the ability of self-attention mechanisms to handle variable-length sequences position our product against competitors using recurrent or convolutional layers?',\n",
              "  'In what ways could the findings on self-attention and positional embeddings influence the future development and deployment of AI models across various industries?'],\n",
              " ['How does the scalability of self-attention mechanisms compare to recurrent and convolutional layers when applied to large-scale sequence transduction tasks?',\n",
              "  'In what ways does the computational complexity of self-attention layers influence their adoption in commercial applications versus traditional architectures?',\n",
              "  'What technical differentiators of self-attention layers position them as a preferred solution in the evolving landscape of AI-driven language models and other sequence-based tasks?'],\n",
              " ['How does the computational complexity per layer influence the overall performance and efficiency of the model in practical applications?',\n",
              "  'What advantages does the ability to parallelize computations offer in terms of scalability when deploying this technology across different platforms or in high-demand scenarios?',\n",
              "  'In what ways could optimizing the path length for learning long-range dependencies impact the competitive landscape of models designed for sequence transduction tasks?'],\n",
              " ['How could the scalability of self-attention layers over recurrent layers influence our market positioning against competitors who rely on traditional recurrent neural networks?',\n",
              "  'What strategic partnerships or investments might be needed to capitalize on the potential performance advantages of self-attention mechanisms in various applications?',\n",
              "  'In what ways does the demonstrated efficiency of self-attention layers impact our cost structure, particularly in relation to training large models for production use?'],\n",
              " ['How could limiting self-attention to a local neighborhood size r impact the performance and accuracy of state-of-the-art models in machine translation in longer sequences?',\n",
              "  'What competitive advantages could be achieved by implementing the proposed approach of restricting self-attention, and how might this differentiate our offering in a rapidly evolving AI landscape?',\n",
              "  'Considering the scalability of this method, how might adjusting the neighborhood size r influence resource allocation and computational efficiency as we expand into larger datasets or more complex language tasks?'],\n",
              " ['How does the proposed path length of O(n/r) impact the overall performance and efficiency of convolutional networks compared to current leading architectures?',\n",
              "  'What specific technical differentiators set apart this approach from existing convolution methods, and how do they influence scalability in large-scale applications?',\n",
              "  'In light of the potential increase in network complexity due to the O(n/k) and O(logk(n)) stack requirements, what strategies can be employed to maintain cost-effectiveness and competitive advantage in the market?'],\n",
              " ['How does the introduction of separable convolutions and self-attention layers position our model against competitors in the current AI market landscape?',\n",
              "  'What are the scalability implications of using self-attention in our model, particularly in handling large datasets or real-time processing applications?',\n",
              "  'In what ways can the interpretability of our self-attention mechanisms be leveraged to enhance user trust or facilitate better integration with existing systems in targeted industries?'],\n",
              " ['How does the demonstrated capability of models to learn different tasks based on syntactic and semantic structures influence their potential applications in various industries, and what specific market segments could be targeted for maximum impact?',\n",
              "  'What technical differentiators in the training methodology, such as the implementation of byte-pair encoding and the choice of datasets (WMT 2014 English-German and English-French), could provide a competitive advantage in the NLP space?',\n",
              "  'Given the significant scalability of the models due to the size of the training datasets, how can we leverage this scalability to accommodate real-time language processing demands in applications like translation services or conversational AI?'],\n",
              " ['How does the use of the WMT 2014 English-French dataset influence the competitive edge of the product in the translation market?',\n",
              "  'What are the scalability implications of utilizing a single machine with 8 NVIDIA P100 GPUs for model training, and how might this affect future growth opportunities?',\n",
              "  'In what ways could the technical differentiation provided by a unique vocabulary and batching strategy impact user adoption and retention in multilingual applications?'],\n",
              " ['How does the choice of hardware and training duration impact the competitive landscape for similar AI models in the industry?',\n",
              "  'What are the potential scalability challenges associated with increasing model size and training steps as outlined in the document?',\n",
              "  'In what ways does the Adam optimizer configuration contribute to technical differentiation compared to other optimization strategies in AI model training?'],\n",
              " [\"How does the proposed learning rate adjustment mechanism enhance the model's performance compared to traditional methods, and what market advantage does this offer?\",\n",
              "  'What scalability challenges might arise from implementing the described regularization techniques in more extensive training regimes or with larger datasets?',\n",
              "  'In what ways can the combination of warmup steps and inverse square root decay be differentiated from existing state-of-the-art training strategies, and how might this differentiation influence investment opportunities?'],\n",
              " ['How does the cost-effectiveness of the Transformer model compare to its competitors influence its potential adoption by businesses in translation technology?',\n",
              "  \"What underlying technical differentiators in the Transformer's architecture contribute to its superior BLEU scores, and how can these be leveraged for future product enhancements?\",\n",
              "  'Considering the training cost advantages of the Transformer model, what scalability opportunities exist for deploying it in real-world applications beyond language translation?'],\n",
              " ['How does the technical differentiation of the GNMT + RL ensemble compared to conventional models like Transformer impact its market adoption and potential for scalability?',\n",
              "  \"What specific features of the model's dropout and label smoothing techniques contribute to its performance metrics, and how might these influence the competitive landscape in AI solutions?\",\n",
              "  'Considering the output performance metrics presented, what are the implications for product development timelines and investment opportunities in achieving higher accuracy in natural language processing tasks?'],\n",
              " ['What are the potential market applications for machine translation models leveraging label smoothing techniques, and how might these impact current industry standards?',\n",
              "  'How does the technical differentiation offered by the big transformer model in this document position it against competitors in the machine translation space, particularly regarding BLEU scores?',\n",
              "  'Considering the computational resources required for training these models, what scalability challenges might arise when deploying them in real-world applications, and how can they be addressed?'],\n",
              " ['What are the potential market applications and commercial viability of implementing this new state-of-the-art BLEU score model in real-world translation services?',\n",
              "  'How does the reduction in training cost and the improved performance of this model position it against existing competitors in the AI translation market?',\n",
              "  \"What are the technical implications of the model's architecture and training configuration that contribute to its scalability for other language pairs beyond English-to-French?\"],\n",
              " ['What potential competitive advantages does the dropout rate adjustment from 0.3 to 0.1 offer in terms of training efficiency and final model performance, particularly within the market of language translation models?',\n",
              "  \"How does the use of checkpoint averaging and specific hyperparameters such as beam size and length penalty influence the model's scalability and its ability to adapt to other languages or translation tasks?\",\n",
              "  'In what ways do the reported translation quality and training costs compare to emerging alternatives in the market, and how might this affect investment decisions in AI-driven translation technologies?'],\n",
              " [\"How does the proposed model's approach to optimizing input length influence its competitive position in the translation market, especially against established players?\",\n",
              "  'What technical differentiators does this model present compared to existing architectures, and how might these affect its adoption in commercial applications?',\n",
              "  'Considering the training costs outlined in the document, how scalable is this model for large-scale deployment in enterprise applications, and what implications does this have for investment opportunities?'],\n",
              " ['How do the performance variations of the Transformer components affect the competitive landscape in machine translation technologies?',\n",
              "  'What specific technical differentiations can be leveraged to improve scalability and efficiency in high-performance computing environments for translation tasks?',\n",
              "  'In what ways can the insights gained from this evaluation guide product development strategies for AI-driven translation services in international markets?'],\n",
              " ['What are the potential market implications of the performance variations observed in different Transformer architectures, particularly in the context of English-to-German translation applications?',\n",
              "  'How does the technical differentiation presented in the varied configurations of hyperparameters indicate the scalability of these Transformer models in real-world applications, and what challenges may arise in deploying these models at scale?',\n",
              "  'In what ways can the findings related to perplexities and BLEU scores inform product managers about consumer preferences and expectations for translation services, and how might this data impact competitive positioning within the AI language translation market?'],\n",
              " ['What strategies could be employed to leverage the technical differentiation offered by positional embedding over sinusoidal methods in developing scalable AI models?',\n",
              "  'How do the performance metrics presented in this document correlate with market trends in AI, specifically regarding the adoption of advanced attention mechanisms?',\n",
              "  'What implications do the variations in attention heads and key/value dimensions have on the potential scalability and market competitiveness of products utilizing this research?'],\n",
              " ['How could the findings on attention head configurations influence the design of next-generation natural language processing models and their market adoption?',\n",
              "  'What are the technical implications of the suggested need for a more sophisticated compatibility function beyond dot product in terms of scalability and performance enhancement?',\n",
              "  'In what ways could the observed trade-offs in model quality with varying attention parameters affect competitive positioning in the AI language model market?'],\n",
              " ['How will the proposed sophisticated compatibility function improve market adoption compared to existing solutions in natural language processing?',\n",
              "  'What technical advantages do learned positional embeddings provide over sinusoidal positional encodings in terms of model performance and scalability for future AI applications?',\n",
              "  'Given the observation that larger models yield better results, what strategies can be implemented to ensure efficient scaling while managing resource constraints in production environments?'],\n",
              " ['How does the application of transformer models in constituency parsing present a competitive advantage over traditional RNN models, particularly in terms of handling small data sets?',\n",
              "  'What implications do the semi-supervised training techniques have on the scalability and efficiency of constituency parsing solutions in real-world applications?',\n",
              "  'Given the significant increase in vocabulary size in different training settings, how might this impact the marketability of products leveraging this technology to cater to diverse linguistic data?'],\n",
              " ['How does the choice of vocabulary size impact the overall performance and market adoption of translation models in multilingual applications?',\n",
              "  'In what ways does the use of larger corpora, such as the high-confidence and BerkleyParser datasets, differentiate this model from existing solutions, and how could this affect its competitive positioning?',\n",
              "  'Considering the limited number of experiments conducted for parameter selection, what are the scalability implications of this approach when implementing the model across different languages with varying complexities?'],\n",
              " ['How does the performance of the Transformer architecture in English constituency parsing compare to traditional discriminative models, and what does this indicate about its potential market applicability in natural language processing applications?',\n",
              "  'What are the key technical differentiators of the Transformer model that enable it to achieve competitive or superior parsing accuracy compared to other established models, and how might these advantages be leveraged for scalability in other linguistic tasks?',\n",
              "  \"Considering the Transformer model's performance across different training methodologies (discriminative, semi-supervised, multi-task), what implications does this have for the future development of parsing technologies and their integration into commercial platforms?\"],\n",
              " ['What implications do the advancements in semi-supervised learning, as highlighted in the document, have for the market adoption of machine learning technologies across various industries?',\n",
              "  'How does the technical differentiation presented in the results, particularly the performance of the Transformer model at a 92.7 accuracy, position this solution against traditional RNNs in terms of scalability and deployment in real-world applications?',\n",
              "  'What are the potential scalability challenges and solutions that could arise from increasing the maximum output length in generative models, and how might these challenges impact future product development in AI-driven applications?'],\n",
              " ['How does the introduction of the Transformer model impact the competitive landscape for natural language processing applications, particularly in translation tasks?',\n",
              "  'What specific technical advantages does the Transformer model offer over traditional RNN architectures that could lead to superior performance and faster training times?',\n",
              "  'In what ways can the scalability of the Transformer model be leveraged to capture emerging market opportunities in AI-driven language services and applications?'],\n",
              " ['What potential market applications can be identified for multi-headed self-attention beyond language translation, and how might they disrupt existing industries?',\n",
              "  'In what ways does the technical differentiation of the Transformer model compare to traditional architectures, and what are the implications for scaling its deployment in real-world applications?',\n",
              "  'What challenges might arise in extending the Transformer to non-textual modalities, and how could the efficiency of local attention mechanisms influence its scalability across different use cases?'],\n",
              " ['How might the development of local, restricted attention mechanisms influence competitive positioning in the market for AI-generated content across different modalities like images, audio, and video?',\n",
              "  'What unique technical advantages could our approach to less sequential generation provide in comparison to existing models, and how could this enhance scalability in real-world applications?',\n",
              "  'Given the emphasis on handling large inputs and outputs efficiently, what potential limitations exist for scaling up this technology in diverse industries, and how can we address them?'],\n",
              " ['What are the potential market applications of the neural machine translation (NMT) advancements discussed, and how might they disrupt current translation services?',\n",
              "  'In what ways do the technical differentiations mentioned in the document enhance the efficiency or accuracy of neural machine translation compared to traditional methods?',\n",
              "  'How scalable are the proposed NMT architectures in handling large datasets across diverse languages, and what implications does this have for global communication and business?'],\n",
              " ['How do the techniques and models discussed in these papers differentiate from existing solutions in the field of machine translation and sequence modeling, particularly in terms of performance and computational efficiency?',\n",
              "  'What market trends or demands could these advances in deep learning and recurrent neural networks address, and how might they influence the competitive landscape for AI-driven language processing applications?',\n",
              "  'Considering the scalability of the proposed models, what are the potential challenges and takeaways for organizations looking to implement these advanced neural network architectures in real-world applications?'],\n",
              " ['What are the potential market applications of recurrent and convolutional neural network approaches discussed in these studies, and how could they disrupt current solutions in natural language processing and image recognition?',\n",
              "  'How do the architectural innovations in recurrent and convolutional networks, as highlighted in these papers, provide a competitive advantage over existing technologies in terms of performance and scalability?',\n",
              "  'In what ways can the findings from these studies inform future product development, and what considerations should be made regarding the integration of these advanced neural network models into existing systems?'],\n",
              " ['What potential markets could be disrupted by advancements in age recognition technology, and how can this be leveraged for product innovation?',\n",
              "  'How does the integration of techniques from long short-term memory networks enhance the accuracy and reliability of age recognition systems compared to traditional methods?',\n",
              "  'What strategies can be employed to scale age recognition technology across diverse applications while maintaining performance across varying demographic variables?'],\n",
              " ['How could advancements in language modeling techniques influence the competitiveness of AI-driven applications across different industries?',\n",
              "  'What are the potential scalability challenges associated with implementing active memory systems in real-world natural language processing applications?',\n",
              "  'In what ways do the technical differentiations highlighted in the explored algorithms influence the ability to integrate these models into existing software ecosystems?'],\n",
              " ['What market opportunities could arise from advancements in neural machine translation as presented in the document, and how might these shape competitive dynamics in the AI sector?',\n",
              "  'How does the proposed linear time neural machine translation approach technically differentiate itself from traditional models, and what implications does this have for performance and user experience?',\n",
              "  'In what ways can the scalability of the methodologies discussed in the document be leveraged to meet the growing demands for translation services in diverse industries, and what challenges might arise in implementing these solutions at scale?'],\n",
              " ['How might the advancements in structured self-attentive sentence embeddings impact the competitive landscape of natural language processing applications?',\n",
              "  'In what ways do the methodologies outlined in the document differentiate themselves technically from existing models in sequence-to-sequence learning?',\n",
              "  'What are the scalability implications of the multi-task sequence learning approach presented in the document, especially in the context of evolving business requirements and data volume?'],\n",
              " [\"How does the Penn Treebank's annotated corpus influence current natural language processing models, and what implications does this have for market trends in NLP technologies?\",\n",
              "  'In what ways do the advancements in self-training parsing techniques from McClosky et al. provide a competitive edge for scaling NLP applications across diverse industries?',\n",
              "  'Considering the differentiated approaches in attention models as shown by Parikh et al. and Paulus et al., how can these innovations be leveraged to create scalable and marketable AI products in the future?'],\n",
              " ['What market opportunities arise from advancements in deep reinforced models for abstractive summarization as discussed in the document?',\n",
              "  'How do the technical differentiators presented in the research, such as improved language models and tree annotation, enhance product offerings in the NLP space?',\n",
              "  'In what ways can the methodologies outlined in the document scale to meet the growing demand for efficient and interpretable natural language processing solutions?'],\n",
              " ['How do the advancements in language modeling techniques presented in these studies influence the competitive landscape for AI-driven language applications, and what opportunities may arise for new market entrants?',\n",
              "  'What technical differentiators do the proposed methods, particularly those involving neural machine translation and large neural networks, present that could redefine performance benchmarks in natural language processing?',\n",
              "  'Given the findings on model scalability and language understanding, what implications do these advances have for the deployment of AI technologies in real-world applications across various industries, and how might they impact user experiences?'],\n",
              " ['How could the advancements in dropout techniques as discussed in Srivastava et al. (2014) influence market trends in artificial intelligence by improving model performance and reducing training costs?',\n",
              "  'In what ways do end-to-end memory networks introduced by Sukhbaatar et al. (2015) provide a technical differentiation that could be leveraged to create competitive advantages in memory-intensive AI applications?',\n",
              "  'Considering the sequence-to-sequence learning framework presented by Sutskever et al. (2014), how scalable are these models in real-world applications, and what factors could limit their adoption in industry-specific use cases?'],\n",
              " ['How do the advancements in neural architectures discussed in the document differentiate them from traditional models, and what implications does this have for competitive positioning in the market?',\n",
              "  'What scalability challenges might arise from implementing the sequence-to-sequence learning strategies outlined in the document, and how could these challenges affect potential adoption by commercial enterprises?',\n",
              "  'Given the evolution of computer vision techniques highlighted in the research, what are the potential impacts on existing applications and industries, and how might this influence future investment opportunities in AI-driven sectors?'],\n",
              " ['How do the advancements in neural machine translation algorithms discussed in this document distinguish themselves from previous approaches, and what implications does this have for existing market players?',\n",
              "  'What are the scalability challenges and opportunities presented by the deep recurrent models with fast-forward connections for neural machine translation, and how might these influence future product development in the field?',\n",
              "  'In what ways do the findings related to constituent parsing in this document suggest potential shifts in the competitive landscape of natural language processing technologies, particularly concerning the integration of machine translation systems?'],\n",
              " ['What competitive advantages does the proposed shift-reduce constituent parsing technique offer over existing parsing methods in terms of accuracy and processing speed?',\n",
              "  'How does this research align with the current trends in natural language processing, and what potential market applications could arise from its implementation?',\n",
              "  'What challenges could emerge in scaling this parsing technique for real-world applications, particularly in diverse language contexts or large-scale datasets?'],\n",
              " ['How might the recent changes in voting laws impact the adoption and development of AI technologies aimed at improving civic engagement and voter participation?',\n",
              "  'What technical differentiators do existing AI models possess that can effectively address the complexities introduced by the new voting laws, particularly in areas of data visualization and user experience?',\n",
              "  'In what ways can AI-driven solutions scale to assist diverse groups of voters while navigating the challenges presented by stricter registration processes, and what market opportunities does this create for product innovation?'],\n",
              " ['How could the insights gained from the attention mechanism in the encoder self-attention impact future AI model architectures and their performance on long-distance dependencies?',\n",
              "  'What advantages does the use of multiple attention heads bring in the context of natural language processing, and how might this differentiation position the product in a competitive market?',\n",
              "  'In terms of scalability, how can this attention mechanism be optimized for larger datasets or more complex models, and what implications does this have for deployment in real-world applications?'],\n",
              " ['How can the application of law be optimized to ensure fairness and equity in various sectors, and what technologies could facilitate this improvement?',\n",
              "  'What kind of competitive advantages can emerge from successfully addressing the inadequacies in legal applications as highlighted in the document?',\n",
              "  'In what ways can scalability be achieved in legal frameworks to accommodate diverse jurisdictions while maintaining a just application of the law?'],\n",
              " ['How does the differentiation of attention heads in layer 5 contribute to the overall performance and applicability of the model in real-world scenarios?',\n",
              "  'What specific market needs does the capability of anaphora resolution address, and how might this influence the competitive landscape within the AI sector?',\n",
              "  'In what ways can the technology leveraging these attention mechanisms be scaled across different industries or applications to maximize its impact?'],\n",
              " ['What are the potential market advantages of prioritizing the equitable application of the law in technological solutions, and how can these be leveraged for competitive differentiation?',\n",
              "  'In what ways can advancements in the application of law enhance scalability for businesses operating in regulated industries, and what specific technologies could facilitate this growth?',\n",
              "  'How might the imperfections in the legal framework impact the development of AI-driven products, and what strategies can be employed to navigate these challenges effectively?'],\n",
              " ['How do the findings regarding attention head behavior translate into a competitive advantage in AI model performance and application?',\n",
              "  'What potential markets could this technological differentiation unlock, particularly in relation to natural language processing tasks?',\n",
              "  'How scalable is the architecture discussed in the document, and what implications does this have for deploying these models in real-world applications?']]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypothetical_vectorstore = Chroma(\n",
        "    collection_name = 'hypothetical_questions',embedding_function = OpenAIEmbeddings()\n",
        ")\n",
        "\n",
        "store = InMemoryStore()\n",
        "\n",
        "id_key = \"doc_id\"\n",
        "\n",
        "hypo_retriever = MultiVectorRetriever(\n",
        "    vectorstore = hypothetical_vectorstore,\n",
        "    byte_store = store,\n",
        "    id_key = id_key\n",
        ")\n",
        "\n",
        "doc_ids = [str(uuid.uuid4()) for _ in texts]"
      ],
      "metadata": {
        "id": "QVX0S17xxFP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GmXJzIkt3d3Z",
        "outputId": "9a62aef9-8ea8-47a9-e61a-34291e6c98ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or',\n",
              " 'Łukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(texts))\n",
        "print(len(hypothetical_questions_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMQKOUNe8wGg",
        "outputId": "afaff623-763b-4b88-b050-f5a168732992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83\n",
            "83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_docs = []\n",
        "for i,questions in enumerate(hypothetical_questions_list):\n",
        "  for s in questions:\n",
        "    question_docs.extend(\n",
        "      [Document(page_content = s,metadata = {'id_key':doc_ids[i]})])"
      ],
      "metadata": {
        "id": "a23xGkXPyzWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypo_retriever.vectorstore.add_documents(question_docs)\n",
        "hypo_retriever.byte_store.mset(list(zip(doc_ids,texts)))"
      ],
      "metadata": {
        "id": "xgC0Fy0C0g8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"Tell me more about Scaled Dot-Product Attention.\""
      ],
      "metadata": {
        "id": "xwc-PYEz6t-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = hypothetical_vectorstore.similarity_search(query=input_text,k=2)\n",
        "for i,res in enumerate(result):\n",
        "  print(f\"{i} . {res}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeYnPkl74zv_",
        "outputId": "dabbe33a-73c6-47bd-d31f-9daf71313bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 . page_content='How does the use of Scaled Dot-Product Attention and Multi-Head Attention differentiate this approach from existing attention mechanisms in the AI market, and what competitive advantages could it provide?' metadata={'id_key': 'e212511b-6df5-4aa0-a390-4fdb69409d8a'}\n",
            "1 . page_content='How does the introduction of scaled dot-product attention and multi-head attention differentiate our models from competitors in the market?' metadata={'id_key': 'a977c015-76d9-4dc9-988d-c17a67069632'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_chunk = []\n",
        "for i in result:\n",
        "  answer = retriever.invoke(i.page_content)\n",
        "  final_chunk.append(answer)\n",
        "final_chunk"
      ],
      "metadata": {
        "id": "WZNs0_g36q6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbb682eb-2b9e-4de6-8a76-ab1f35e43d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Scaled Dot-Product Attention\\nMulti-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1\\nScaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\\nvalues.',\n",
              "  'multi-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs',\n",
              "  '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',\n",
              "  'checkpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected,',\n",
              "  'In this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.'],\n",
              " ['Scaled Dot-Product Attention\\nMulti-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1\\nScaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\\nvalues.',\n",
              "  'checkpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected,',\n",
              "  'multi-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs',\n",
              "  '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',\n",
              "  'has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.']]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KXlWQzp6J2Nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_chunks(user_input):\n",
        "  result = hypothetical_vectorstore.max_marginal_relevance_search(user_input)\n",
        "  final_chunk = []\n",
        "  for i in result:\n",
        "    answer = retriever.invoke(i.page_content)\n",
        "    final_chunk.append(answer)\n",
        "  return final_chunk"
      ],
      "metadata": {
        "id": "lgoADx7FECoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(model='gpt-4o-mini')\n",
        "\n",
        "prompt = f'''You are a research-level AI assistant specialized in technical and academic content.\n",
        "\n",
        "You are given retrieved multimodal context from a RAG system.\n",
        "The retrieved context may contain:\n",
        "- Plain text passages\n",
        "- Base64-encoded images (figures, diagrams, charts)\n",
        "- Tables formatted in markdown\n",
        "\n",
        "Your task is to generate a clear, structured, and technically accurate answer\n",
        "STRICTLY grounded in the provided retrieved content.\n",
        "\n",
        "-----------------------\n",
        "MULTIMODAL INSTRUCTIONS\n",
        "-----------------------\n",
        "\n",
        "1. If you encounter Base64-encoded image data:\n",
        "   - Treat it as an image.\n",
        "   - Decode it mentally and extract visible information such as:\n",
        "        • Titles\n",
        "        • Axis labels\n",
        "        • Legends\n",
        "        • Diagram structure\n",
        "        • Equations shown\n",
        "        • Annotations\n",
        "        • Visual relationships between components\n",
        "   - Integrate relevant information from the image into your explanation.\n",
        "   - Do NOT ignore images.\n",
        "   - Do NOT hallucinate details that are not visually inferable.\n",
        "\n",
        "2. If markdown tables are present:\n",
        "   - Analyze numerical trends\n",
        "   - Compare rows and columns\n",
        "   - Identify key patterns\n",
        "   - Summarize important results\n",
        "\n",
        "3. If both text and images describe the same figure:\n",
        "   - Combine them coherently.\n",
        "\n",
        "-----------------------\n",
        "REASONING PROCESS\n",
        "-----------------------\n",
        "\n",
        "Follow this structure internally:\n",
        "\n",
        "STEP 1 — Extract Relevant Evidence\n",
        "- Identify relevant text excerpts\n",
        "- Identify relevant image-derived insights\n",
        "- Identify relevant table insights\n",
        "\n",
        "STEP 2 — Interpret Evidence\n",
        "- Explain what the evidence means\n",
        "- Clarify technical concepts\n",
        "\n",
        "STEP 3 — Provide Final Structured Answer\n",
        "\n",
        "-----------------------\n",
        "STRICT RULES\n",
        "-----------------------\n",
        "\n",
        "- Use ONLY the retrieved context.\n",
        "- Do NOT introduce external knowledge.\n",
        "- Do NOT hallucinate missing details.\n",
        "- If the answer cannot be derived from the context, say:\n",
        "  \"The provided context does not contain sufficient information to answer the question.\"\n",
        "- Be precise and technically rigorous.\n",
        "- Use headings and bullet points for clarity.\n",
        "- Explain equations or diagrams clearly if present.\n",
        "Question:\n",
        "{input_text}\n",
        "\n",
        "Retrieved Context:\n",
        "{final_chunk}\n",
        "\n",
        "Provide a detailed, well-structured answer grounded strictly in the retrieved content.\n",
        "If base64 images are present, extract and interpret the visual information.\n",
        "If tables are present, summarize key findings.\n",
        "\n",
        "'''\n",
        "\n",
        "answer = llm.invoke(prompt).content\n",
        "res = answer | StrOutputParser()"
      ],
      "metadata": {
        "id": "P4k9Dce1933M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "482642df-671f-4e39-ccb9-c58cecfd9403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Scaled Dot-Product Attention Overview\\n\\n## Description\\n**Scaled Dot-Product Attention** is a fundamental mechanism used in transformer architectures for enabling models to weigh the significance of input parts when making predictions. The primary components of this mechanism include:\\n\\n- **Inputs**: The attention mechanism takes as input:\\n  - **Queries** and **Keys** of dimension \\\\(d_k\\\\)\\n  - **Values** of dimension \\\\(d_v\\\\)\\n\\n## Computational Process\\n1. **Dot Products**: The attention mechanism computes the dot products of the query with all keys:\\n   \\\\[\\n   \\\\text{attention scores} = Q \\\\cdot K^T\\n   \\\\]\\n   where \\\\(Q\\\\) represents queries and \\\\(K\\\\) keys.\\n\\n2. **Scaling**: The dot products are scaled down by dividing each score by \\\\(\\\\sqrt{d_k}\\\\) to prevent large values that can lead to saturation when applying softmax:\\n\\n   \\\\[\\n   \\\\text{scaled scores} = \\\\frac{Q \\\\cdot K^T}{\\\\sqrt{d_k}}\\n   \\\\]\\n\\n3. **Softmax Application**: The scaled dot products are fed into a softmax function to obtain the attention weights:\\n   \\\\[\\n   \\\\text{weights} = \\\\text{softmax}(\\\\text{scaled scores})\\n   \\\\]\\n\\n4. **Output Calculation**: Finally, these weights are used to compute a weighted sum of the values:\\n   \\\\[\\n   \\\\text{output} = \\\\text{weights} \\\\cdot V\\n   \\\\]\\n   where \\\\(V\\\\) represents the values.\\n\\n## Visual Representation\\nFigure 2, referenced in the context, depicts the architecture of Scaled Dot-Product Attention alongside Multi-Head Attention. The visual shows how multiple attention mechanisms can run in parallel to capture different aspects of the data.\\n\\n### Key Features in Figure 2:\\n- **Left Side (Scaled Dot-Product Attention)**: Illustrates the components (queries, keys, values) and processing steps (dot products, scaling, softmax, output).\\n- **Right Side (Multi-Head Attention)**: Shows that multiple layers of attention can function simultaneously, which allows the model to gather various features and relationships from the inputs effectively.\\n\\n## Performance Insights\\nThe retrieved context also mentions the influence of attention heads on model performance. In Table 3, varying the number of attention heads affects the quality:\\n- **Single-head attention** shows a drop of 0.9 BLEU when compared to the best configuration.\\n- Reducing the attention key size \\\\(d_k\\\\) negatively impacts model quality, indicating the necessity for an effective compatibility function beyond mere dot products.\\n\\n## Conclusion\\nScaled Dot-Product Attention forms the backbone of the attention mechanism used in transformers, allowing models to dynamically focus on different segments of input data. The emphasis on proper scaling and multiple attention heads has been crucial in achieving significant improvements over traditional recurrent and convolutional network architectures in tasks like translation.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "data = image_list[1]['image']\n",
        "img_data = base64.b64decode(data)\n",
        "img = Image.open(io.BytesIO(img_data))"
      ],
      "metadata": {
        "id": "t7P0j9Jc6c6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "id": "7rKBghTMWEm3",
        "outputId": "c7372611-9040-4e22-f967-83a06800897a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=445x884>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAN0CAIAAACvNGFGAAByPklEQVR4Ae29C/huU7n/bb2v/w6xbHJqsSqUJYmEKMoxkkTlVCFpi5zaapdESORU2hGlcqxsxHYom+RYsYnSkpw2VjlFTv9NUXtf77Xe72os9xprzvmMZ875zOOYH9fvWsYz5hj3uMfnnvP7jDnGmPOZMnv27AX4DwIQqI7AlClTZIwrqzqinbP0/3TOIxyCQBQEnHpG0RU6kSSAbiaJ8BkCEIBAmAC6GebDUQgUI+APM/10MSuU7jYBdLPb8cE7CECgewTQze7FBI96S4ABZm9DV8xxdLMYL0pDoBABlLQQrr4URjf7Ein8hAAEukIA3exKJPCj7wRGDS1H5fe9v0P2H90ccvTpOwQgUIYAulmGGnUgkCDAoDIBJO6P6Gbc8aV3nSCAqnYiDNU5gW5WxxJLEIDAMAigm8OIM72sk0Ce4WSeMnX6iO0qCaCbVdLEFgQgMAQC6OYQokwfayTAQLJGuF01jW52NTL4FR0BFDaakKKb0YSSjkAAAg0RQDcbAk0zURIoOoQsWj5KaBF0Ct2MIIh0AQIQaJQAutkobhqLiQCDx5iiWagv6GYhXBSGwKQEUNtJCXagPrrZgSDgQg8JIH89DFplLqOblaHEEARyEkBzc4LqbDF0s7OhwTEIQKCjBNDNjgYGt7pMYPIB4+QWuswnet/QzehDTAchAIGKCaCbFQPFXPQEMoeKs2fPDnQ8fDRQkUPdJIBudjMueNUbAtLEPLKYLpapv73p9rAdRTeHHX96PwGBtBSONZZHYccaoUDrBNDN1kOAA30iYIPE0gpYQm37BGgYvi44jG7SSwhUQ6C0XCaar8pOwiwfmyHAeLMZzrQCAQjEQwDdjCeW9AQCEGiGALrZDGdagQAE4iGAbsYTS3oCAQg0QwDdbIYzrUAAAvEQQDfjiSU9gQAEmiGAbjbDmVYgAIF4CKCb8cSSnkAAAs0QQDeb4UwrEIBAPATQzXhiSU8gAIFmCKCbzXCmFQhAIB4C6GY8saQnEIBAMwTQzWY40woEIBAPAXQznljSEwhAoBkC6GYznGkFAhCIhwC6GU8s6QkEINAMAXSzGc60AgEIxEMA3YwnlvQEAhBohgC62QxnWoEABOIhgG7GE0t6AgEINEMA3WyGM61AAALxEEA344klPYEABJohgG42w5lWIACBeAigm/HEkp5AAALNEEA3m+FMKxCAQDwE0M14YklPIACBZgigm81wphUIQCAeAuhmPLGkJxCAQDME0M1mONMKBCAQDwF0M55Y0hMIQKAZAuhmM5xpBQIQiIcAuhlPLOkJBCDQDAF0sxnOtAIBCMRDAN2MJ5b0BAIQaIbAlNmzZzfTEq0UJTBlypSiVSgPAQhMSCCPJKKbE0KuvjpyWT1TLEKgOIGAgKKbxXHWVgPFrA0thiFQkkCmejK/WZJm5dUQzcqRYhACkxPIvDDRzcnBVmAhMzYV2MUEBCAwMYH05YluTgx1YgPpqExsEgMQgECVBBIXKbpZJdwSthLxKGGBKhCAQAME/EsV3WwA+Mgm/EiMLMQBCECgGwTsgkU3WwuIxaA1D2gYAhAoSMBdtgsWrEXxpgnsvdcByy+/YtOt0h4EBkbg0Udnfeu0k3J2mv2bOUFVXCzPYPPznz9q843e97L/s0jFbWMOAhDIIvC3/33h6hsu/vKXD806OF8eujkfjsY+jNXNb5z0vbVW37Axf2gIAhBwBG6/8xf7HbBrmAbzm2E+7Rz9yvGnIZrtoKfVwRPQpadRSxgDuhnm08LRXXfZ463rbNFCwzQJAQj8nYCkU5dhAAa6GYBT16HwTfomG72nroaxCwEI5CMQvgzRzXwUGyw1Y+W1GmyNpiAAgQwC4csQ3cxA1mLW+7bbocXWaRoCEDACgYsR3TRKnUgsuuhinfADJyAweAKBixHdHPzZAQAIQKAgAXSzIDCKQwACgyeAbg7+FAAABCBQkAC6WRAYxSEAgcETQDcHfwoAAAIQKEgA3SwIjOIQgMDgCaCbgz8FAAABCBQkgG4WBEZxCEBg8ATQzcGfAgCAAAQKEkA3CwKjOAQgMHgC/E7G4E+B+gHcNvOGTx64u9/ORedfv9zSr/ZzSqd/cv0FRx55kFXfYoutDv/cqfaxI4mICXznnGPOOuvb4vyZzxy23VYf7Qjwut1gvFk3YexnEJj5u1sycotn/e1//nLeeWcUr9d+DQi0H4MJPEA3J4BH1bIEqhK7395923333VvWiwrqffHYfTbYdEX9/fyW/yhkLhoChXodTWF0M5pQ9qkjEru77rt1co9vn3nT5EZasQCBVrBX1Si6WRVJ7BQj8Js7bi5WIVX62ef+5GbWUkf6kQGBfsQpy0t0M4sKebUR2H77nZ3tU049UbOTk7Tzy19fb9XNrOV0NmGuDpZAZ0OT3zF0Mz8rSlZAYJ21325Wfnn7DZYukbApQq3kLrro1BIWWqkCgVawV9soulktT6yNIbDwQi/fd59PuUK3/ernY0qPPqzpUVsRWnP19UYX7NwRCHQuJMUdQjeLM6PGZATetMb6zsCFF573+JN/KGfsxpuvdhW1YXPF6auVM9JWLQi0Rb6qdtHNqkhiJy+B1VZZd5VVZrjS5bYx+itCm27Sv59NhkDec6Wr5dDNrkYmar923nkP1z+boyzU3Tvvvs3Kv2WtjSydP6HtlvpzWy/9f11+fjulS7ZOoLTnVBQBnrPkNGiBwJpvmDsj6bYxavxVyIlrr/uxK6+p0pf9w8sL1U08l5mo+7mD93U5xx5zytvXe3fiqD5ecsWZJ5xwZDrfKtqhG6+dZel0onkC2qJ/1VVXyJNRXUs76XL0veIS3z/78t5NiYzq1IT5jDcnBEj1MgT0cLptxym6jVErQu76V8NvXW+z/M1rLlXa4T/MHqgrHdST14ECEx5qhcCEPlPdCKCbhoJEowTevsG7XHtFtzGazhZaEdKU6GmnH2eCK9XWsOvaK+/UqND+vvOtCw477DijoE31Gl3ax8oTDROo3P8hG+Q+fcjRb7Pvb3z9OlodcnuJtJEz86Y47Z+2yktnXX6hFaELLzndRPPrXztrnTUzZkU1XaC/t7x547O+/zWt9asV3ZJrk5N/c6pX/vhv/Sl98yvjDRNIwySnNAHGm6XRUXEiApqX3HbbnZwJm68ca9HfKr/669cZW94VmPXwXfZEpoaZmaJpppaYuszuuxxoH+974E5LV5tokkC1nmMN3eQcaI2A7VfXSFDSlscPU1itCEng8lRRmZl3zn1tnW7P8wxsZVnPIDnjd911e85WShRrjEAJ36gSIIBuBuBwqF4Cuv/VHKVrw6Qt0KS01e61bet4oLwdmjlz7ruX/Gcc7Whm4hVLLuvy77ijRt1sjEBmH8ksTQDdLI2OihUQsDnKSy89f+xrPkxbNTGaf+uSzJravmKJpXM6rachXUl7mjNnxaLFGiBQ1CXKjyXAutBYRBSokYDNUUqe9BLiwMyj5E/a6lzZ46MHFPJJc5qu/CuXe3XOii/+daJ3NeVsRcWaIZDfH0rmIcB4Mw8lytRFYM4izO4fd9bDLyHWipAN/Uxr8ril5RfNabq//FOiDz/8QB7jk5dpgMDkTmIhQQDdTADhY9ME1lrzba5JLXlrl+Wo5u3lSdLZ/PI3ylo4X88U2W6ncMlKjnaQQCX9itgI9+kRB7cfXfO3MerB88z1bj3q4zZUqkumMpV0T0ptT7s//cwTmc9QVtJQwEi7BAKOcWgUAXRzFBnyGyLgtjE6wdI2o0zdvPm2a503WhEKzIHm8ViL8o889nuNXk2I07W0yr/++hvnfCIzXb1oTsMEirpH+TQBdDPNhJymCfjbGHf78F3+8zlyxV8RstcIlXBR7zo648yTbJLUtyA5trUmJ9z6xXO/QN3pZgjU3Yvh2Ec3hxPr7vbUbWN0u4W02Sihm/6P/dprhAp1Zs77Ol96dNJV1CTpqjPWXGHaaxJtFTJbYeG6CVToKqZEgHUhToNOEAhsY7R1domdXiNU1F0NV0869Qi7K9ebO/Q6jz13O1jjyo6IputRfQSKEvPLi57/kbQjgG5yJnSCgG0tchs5zSetCNmj5eVWhK645gLb9643SG658Y6aTzT73UnUR2CSPj77309NUj3WuuhmrJHtWb9GbWO0H9LQFKTWnUv0ynbLa/d7pwaYib7URyDRUKGPzzw7cmdYITuRFUY3Iwtoj7tjw0l/I6f9kIZenlRinKjhqi0EFfpFjaeffaJ5lHUQSPfihRf/nM4clfPwY7NGHRpyPro55Oh3q+9uG6Pzye2p9H/sd/11Ni3hrv+4ZCHZvfnm60s0N2GVOgiYS1OnLu7STz9V4CuhFQ7mc2cT6GZnQzM4x9w2Rtdt9744+7Ffvf+txIqQTL344rxljfxLHNqEZFOiTYahDgLm/7LLTHPpn159uWWGE21xCHvVhaPoZheigA9zCfjbGHXR2opQ/ve/JVAuucS8d3RqP1PiaOZHbVo65ZuFf1mo0M1vZrsus3IC1tb06Su7tCYucr7t9PIr5r5IxYyQcATQTc6EDhHQuo39XpuJl1aECk1N+v1ZYvGl7KNUYOyQ0+30lLLYi0GtembCbn4feqia94BUTsDcft1Kb7D01dddaulRCf22kht050Qxyk6U+ehmlGHtcadsaGnrOeVWhBwC3fnam9ulAuecd1JAOjXC/dRnd9NOTyn1Xh87yCAGRmd286uhsZ5HsiqTJKolYJ74v6Apb8M/OXfuhSe7J1+1CWHatOlmhIQjwPNCnAndIpAeWtqtazlHN9pga3tbh/Tipptu0COV2ixpL1VyT6xrRtXmNA875ESpjNTTafcuH9la8qE7ce39TPiwyuvWsJzET6iHfz/daqUTlROwJrbbZlfb/y8meg2+Ntv7KPSlovf1GQr3syL33DvTLJBwBNBNzoRuEdAIUb8dZK9x003ihJsupY/6gd89954reZLChMAl+q/CrkWNc01wXZW0buolIxIXE6OEqXIfKydgbqhf+gKw7ut7wr4qrIwl9HTWbjsXez+01Y0+wX169CHuXwf93w6ypw8n6YZ+VENPCo2dp5MCXnT+9fYLHFtttqO0Y2y7B+5zjMQoT8mxpqxA5QTMsp4u1ReDhtKWk5nQTyXrUVQpeOZRMqfMnj0bCg0TmDJlyqgWd91lj733+MKoo+RPSEAbQp9+9snEW5Gkp1LnwDs+dPcan4JoMld7+xPvytPD+4ssvGjiVX4q6bbB+nf0EwaiF9W/dcaXvvf9MzJd5T49EwuZcRJwY8mELoztanyiqS6715imZx7SNCZ84WnaYAQ53KdHEES6AAEINEoA3WwUN41BAAIREEA3IwgiXYAABBolgG42ipvGIACBCAigmxEEkS5AAAKNEkA3G8VNYxCAQAQE0M0IgkgXIACBRgmgm43ipjEIQCACAuhmBEGkCxCAQKME0M1GcdMYBCAQAQGeT28hiIHn0+VN6fePtdATmoRAvAQ22HTFUZ1jvDmKTGv5Tzz1UGtt0zAEIPB3AuHLEN1s4TQJv4Pq5zdd2YJPNAkBCHgEwpch9+keqgaT4Vv1f7/ghmWXelWD7tAUBCAwj4AGm+/fcaN5n1MpxpspJB3IOOW0o//2vy90wBFcgMDgCOjS0wUY7jbjzTCfuo6Gx5tqdcUVVzr6i6e8eoVV6/IAuxCAQIrAHx6555DD950168HUkfky0M35cDT5Yax0yhm9/n29t2wybblXcdveZGhoa2gEdGP+2OMP3fLL60a94N0HovUJdNMH0mg6j2426hCNQQACOQhIN5nfzMGpniLhVfV62sQqBCAwEQF32aKbE0GcsDLSOSFAqkOgFQLoZivYaRQCEOgfARvooJstB88i0bIfNA8BCAQJ+JcquhlE1chBPx6NNEgjEIBAMQKJi5T19GL4ai3NCnuteDEOgRIEEorpLDDeLEGyriqZEaqrMexCAALjCIy6JNHNceSaPa44uf/qaFbPINVhFpsQiIzAS1fh7FH9WnDUAfLbJaDIVeuAJgFmzFj1wQcfqNYs1iDQAAE3hVX5RVHac+Y3S6PrWUWbPO3OydczgrjbEoEOnrrcp7d0LjTbrJ15zTZLaxCIkwC6GWdc6RUE4iDgf+X76XZ7h262y7+F1rtz8rXQeZqEQBUE0M0qKHbbBkLZ7fjgXQECHTmZ0c0CMYumaEdOvmh40pGaCHT2REU3a4p4V8x29szrCiD8gEBxAuhmcWbUgAAE6icw6it/VH79Hs1rAd2cx2JQqS6cfIMCTmdjIoBuxhTNZF8QxyQRPkdBoPUTG92M4jwq1YnWT75SXlNpEAQ6fnKim9GehR0/86LlTscGQADdHECQ6SIEekUgz1d+njL1dRrdrI9tDyy3e/L1ABAuQiCLALqZRaX/eQhi/2M40B7kP3Xzl6wcJbpZOdKeGWzx5OsZKdyFwEsE0M2XSET0f6QwomDSlS4SQDe7GJWGfUJnGwZOc6MIFD0Vi5Yf1W7RfHSzKLGul2/rTOo6F/yDQHUE0M3qWGIJAhCYgEC5r/xytSZwc05VdHNCgJFUb+Xki4Qd3RgeAXQzqpgjf1GFk87kI9D8aY9u5ovMAEo1f/INACpdzEugX6cfupk3rt0v168zr/s88RACowigm6PIkA8BCDREYPKv/MktFOoqulkIV+SFGz75IqdJ9+IlgG5GEtsSkjd79uxIOk83oiMQPjkzj5a4BEpjQzdLo+t0RZ1YmedWwul0sSZPvoQzfBwmgcQplz4nM7HkLJZZd/LMBSc3gYXWCfhnXh65TDisKr6FxFE+QqAZAuVOXfnW/NnLeLOZU6KJVib5Bp6kbhN9o41ICZjklRBNQ2J1zZodqinBeLMmsI2atfNmwlarsjOhG1QfDoGqTrmq7OQkz3gzJyiKQQACEJhLAN3kVIAABCBQjAC6WYwXpSEAAQigm5wDEIAABIoRQDeL8aI0BCAAAXSTcwACEIBAMQLoZjFelIYABCCAbnIOQAACEChGAN0sxovSEIAABNBNzgEIQAACxQigm8V4URoCEIAAusk5AAEIQKAYAXSzGC9KQwACEEA3OQcgAAEIFCOAbhbjRWkIQAAC6CbnAAQgAIFiBNDNYrwoDQEIQADd5ByAAAQgUIwAulmMF6UhAAEIVP/7Qo39NBLBK0pg+vRXPfzwQ1aLSBmK1hMN/zxO6/3tuwNTqgoYF2HfTwX87wKBqq7HLvRlQh8CktI6pQrGm4HuTQiO6hAYGgF3NbWuC0PDXrS/k85vIppFiVMeAmMJ6LLiyhpLqcUCE+kmoW0xcjQdPQGur86GuLxuEtTOBhXHoiHAVdbNUJbUTcLZzXDiVXwEuNY6GNMyukkgOxhIXIIABBojUFg3Ec3GYkNDEHAEuOi6diZUsA8ps0ubbf7OadOXzzxEJgQgYAS+d+ZZlg4kJJ1sTgrwafhQsWDk+d7be//9tv7gu1+54isb7gnNQaCPBP76l7/ecNkN3z3527NmPRj2f2i6GVCb1lFUrJvf/MF319107XD4OQoBCCQIPPPEs9/80ikXX3RRIt//2LpY+M40kB6KbiKaDZxMNBErAQ08D9/7sGuu/mmgg4OSzi7rZoF1oUA3FGndnjPSDJzxHIJAmMBCL19or4M+ES7D0Y4QKKCbYY/f/7H3hwtwFAIQCBNYafUVd/3o7uEyHO0CgWp0830f+MCSyy7Rhf7gAwR6TeBtm2/Ya/8H4nw1uvma1600EF50EwK1EnjFMkvWah/jlRCoRjeXWuYVlXiDEQhAAALdJ1CNbna/n3gIAQhAoCoC6GZVJLEDAQgMhQC6OZRI008IQKAqAuhmVSSxAwEIDIUAujmUSNNPCECgKgLoZlUksQMBCAyFALo5lEjTTwhAoCoC6GZVJLEDAQgMhQC6OZRI008IQKAqAuhmVSSxAwEIDIVAXb+T0Vl+zzz+zG9umvnU408d/6UvJ5zc78BPvuq1r37FskutucEbE4f4CAEIQMAIDEg37595/5UX/eSs73zXOp9IfONrX7ec40858a1brL/wogtbTruJa//9ul/+7JYLzz/f3Dj5rG+9dcv17GPOxH/+5Jb9d9/bL3zpLy5ffuVpfk7p9I/PufyIgw616lu8611fPvMY+0gCAtEQGIpunnX8Wb4sjo3fZ/f9lMqU06axxgsV0AD5KwefcNWVVxaqlb/w7TfeXoluvvjnF889/Xv526UkBPpLIH7d1PX89UO/7o/Udt/zn1Z702oz1pzh64WK/edVNz90/x98edXQTDfvu3929xYDnEc0P//Rg52wapi86fs3KeStxO49u21dqEpm4d/ceMd9992beYhMCERGIH7d9EVz+5122nX/3Xy5tHDqltwpznt3e+9l51xm6qnEIou+fMd9drCSTSZ0W20jTSm4fFtyuSWrdUBiN/PG304+pfurG2+r1jGsQaCzBCJfT9e0oI00Ncz83L9+LlM0/fBImDTA1B26ZWoFSfplH5tM3Dvzbtec5grlVeWi6YzffuOvJuyUJhMCE8cTGqc6BLpGIGbd1K33d79+miMu3dnvyH3z09eSiy+dJ3/5a7KWv3pVJR9/7HFnavNttqjKptnR6NulNaaesHc3XfWfabOWQwICkRGIWTfvm3m/zbhts/N2RSMn6dStsaslO5r9LGph8vJ33P4bZ2Thly8yubWEhbe8Yz3LmbB3tiL02S98ftGpi5lZEhCIkkDMuvnwAw+5mK2yyowSW3ZUV/OJFnVtA7J0YwnT/TpalBbbF8MkvdP0qPn55g3WqsNVbEKgUwRi1s3f3/97x3qNtd5UDrrmE+1m1uZJy5nqZq21NljbOabePfrAY+Wc/PlPfuYqajLktWu+tpwRakGgRwRi1s3HHn7ERWKSO8fV3zzv2SGtfvQotHlc1TK6BuOupDZy5qmSKOOvCNUxCZtojo8Q6AKB+PchifKfn3u+NOtV15yhTZGues7Hh7SIr/Ju57y16zaNvulta9a0Jm4NFU186GO7uod8ym3k1EOr1qKesLJ0oUQmMVlw5IvuSC3UNIUhUIJAzLo5bfoKjohWV7RenFP1EhB145n/3lPXf0IuzZpt09GU4js/sMWo7VAXnPrD9IPzMpJ4OFIqbAatCSXmtD7/roHb/jhmFLnWSzOSmqMssZHz6h9d5RxQv0oQTjya6fdlbnf0v33nCGhaPRVTf3NuZpmEQfdRFb+0/5G2MbYLT4Vl+klmZwnEfJ/+mte+xnFvYDVct6vH/vOxo0TTD782/Wy74dZuhOXnt5WWgtscbtGNnNJZU58Nt9ywUBc0narHnPzn2QPVBfYbh52SKCCZ/vjnPm7zDCqTc4r2/FPPN7eltuXWDBPO8HFQBGLWTd1iWyx1Uem9Hvax2oQu1/122sdfONLVeN6VP9RYz/6UY/Kk1uWPhpbVulHa2kZbzX00s+hGTtPZoitC+po55aiTTbxERnx+/l83GS4lTr/wnCOOO8o6pfF1mpgmPQ768iFWRjbHbkTVN5a66apojJwexpo1EhAYRSBm3dT9te5nrec7v2sH3RXax6oSkoDP7PEp24ijS1HXv67GxN29cvS0krTAxke6H0+POvVAp68d5qTuJf187eH3P0q2XEmpj5+vtFkIJN60wRrmVf6NnFIoE6CiK0LnnvpvJprqmsiIT+I2X2tWenD+qtuvse8bEUt/+amYyatsaiwZ6Km+4fSN5QoI2k777BQozCEIjCIQs26qzx/a54OmCPqou8J1XrmW3o0kwZLejYJSKF8SYKIp2dLTkInr37emi/yEM040l/LfWvpGKk/L4e12+oAza/OVY1vxFVbrXWPLWwFpn03Oilj4NlkjSt2MW917Zt5raUtIXk1bJeXpbyNXUkKvAanV2vfQ/QORsmIkIJAmELlu6qqTTtlwzPVfl5YEa4u1NpOG6tZvEg3Vc+smATlv+jSfKJcsEheffbGlW0zYfnUN2dJjukzHTGHV8UKbBH790oYniV2e22QZ12NIzoc7f/3bTGekrRblUd9GiWnNUUtzmfbJhIBPIHLdVFd1eXzh5MPsVs7vvNK69ZtEQ2+44jpnUEPI/Dd9cknjLFdRsptTpxKeV/tRswqmO6ZrgSbks91o2+b5QHn/0G9u/bX76D/o6RdIp5dabimXaQ+eJspIWzV+tMz0RKe+HW1WIec3nFkjAYEEgfh1Ux3W7Zhu5TTZJ7WyG7oECH30NVSX2djFWRWwtaB/+uRehW76tNXR7tZ/8ZNfpJ1pPsfmKC85/6KxqyumreqFJh/yeyvLJrj6SZKcFe3xfJsSSVf0v40SE52ak9G3o6vCtGYaHTlFCQxCNw2KW5xxAioNNeWyApbQZabdQtpapK02lplI+A/YFN3yLZHVhnNn8KrLrxyrU4mm6/hoc5TSJr2EONCEvJW2ugL6wgiUzDwk8u5v+srLZxZIZ774lxfSmekcxVdjSZfvT3R++9hvW2GmNQ0FidIEFixds9cV3bSa+9ctI+iNc+mxjIaT+tOlqHvw9HDS5tpUIH10LB/bJqV2H33g0cT6+9jqlRfQra5tp9dLiAPLNVoRMlamtjn9ESiHPWd5V0zv4c9ZXpG67+573ZBWX36nL3uOXu9itwXSa6Y1c5KkWIDAsMabmSB0Gevv3BvO0zhUe2LSM6EauejxkvT6u12N+hXMTMvhzOW90dZDDzwcLtzM0bU3WMc1pFnXdH/NB3t5knS20IqQWSiU0O4xm5ocW1G67E90fmz73WxrPdOaY+lRICcBdHM+UBpkuZlQCaitk6iExi/+vZ5yfFnJP0/nN6Yr3CZbX/hzrvtQv3odaX8jp//gud+WP6trOusXmCQtqhr+uz9tddCGB/2Z8OW07E90WhWhbvd3oswTEhEQGOh9+tjISUD197ZzNrSLVqNLrf/aPeaLf/mrGVlquVdYulDCXtTUEd2UlGsjp9bH1AttM7LO+p268Sc3uo+aHQ7cy/tVAmmty2usnfiJ40R5fYG9bZN5gUgczfwoz/e7/5M2SpWr/ibQzCpkQiA/AXQzxEpjz0UWXcSWYjUHalLyojdCXPjlC4Ws9OqYv5Fzj5kfS8y6+itCtq5Vrn8aVGbOKcuaZM6WmxzwCX/fSbOx/vdcOYepBQEjgG4aiuyErtvdfzP35UN/X8B5zC0sLLzovB+uiOmadBs53bqKNhsldNP/sV97kVI2uNG5uhnXpIfNDqug5kn1y8yvWnl6ornRNsYckSjbYNMV1Y5ObePVgHpMTQ5DIAeBOOc3dWW6qTH9q0soB4dQEX8W76H75y7g+GPMpx5/OlR/9DF7MahGtaNLNX0ksJHTfuxXSlduYVojVv0ivImmVuH0OL8et9f3U1WimXgI3eFL7OhsmintxUUgTt30YzT51OGrXjvdDNpGQn8d+eknnrIC+RNSEJOPTummbS3S+NrfyCk9sodK/e+S/F1WyR+d82M3mFVar4zSTEi1Y0B9Zeo1K84lTYxqjJm5o7OQzxSGQIJAnLrpX4pPPf5kos9FP/pDS7+urYbn313oV9eeTfuoW1RLt55wGzmdGzbA1Efb56/5R628l/PTNsxrK2VVA0zfE80A2N5St8VdOzpta4SmqqX+fnnSEChBIFrd1LXtcOhpnBJc/CrPPPGMfbQH/pRjPz2kqTQNHq1MzoT/ah9/L2fO6rUWs+Gkv5HTfuxXa+7+N1N+T6RZJmqFnrDKOaLXTk8bwtsWd7nq7+jUaFRj0vw+UxICaQJx6qb6ucXWc19JqQs18Kxkmkg6x9+U7t+z2wM/quK/VC1tIZ0jnTUZKve4UdpmhTnpjZxiaJK3wZYblGtrvk0IRZZobrruF2NblIe2aUzTr7bzQRX9HZ3qRWIr7ljLFIBAgkC0uum/pOf8756b6Hb+jxI4bZdx5TWG9RdDdJtpN4AqU2jI6T+q6Lua37FaS2qMlngjp/3Yr2YnfAiF3PiLNyrPj0ubkGxKdFRzGkIe9/mj3VGFSe9dTZSUjNpEp8akdbzBOtEiHyMmEK1u6iU9Jmq66kpfJ3ppo42zbFOhnRDb7LydS6tM+E3jVkWJxIJvofcJ+XbS6ckXwcymv5HTf81o/pe/mSlL+A8I+CtOViCdkCCe/OWvpfMTOf60pn45w1+1s5L+RKdGphPehZhZEgMkEK1uKpY7/dOHLKK6TkpIp94Mb9sANYpJT8npgRlbHVLJPHueJJq24Cv39vjnj5mTpRNTF1/c1f39/b8vbSRRUaNp65opVyaERMXAxyWXXcKO/ui8S8YOOSWaThDtK9Cq+wl/WlMbm0Z9DyUmOjU+ZaLTx0g6P4GYdVPXj/+SDkln+L1wPjUNRvRriyaaOqRRTOZiSOInFSW1ATmQWf/HiOReJWvKy01bzjmvZZw82u33NJC2oaWNuEuvCLlWBNDe3K6bgNOPPyPASoNc92t3Emt/YSfxmmd/WlNCr41NgR4x0RmAw6H8BGLWTVHQVeRLpya29IIctxle+pLekqJrVfkf2mhnFfPn1PSaj1GjGN0S+j8ZJKl9++veJiOJy1s5Um2ZNQ2SgoQv8vxRnLHm662wttrYnn8lLL9EIj2+tpv3EtZclc3fv5nVlcp/bOuPiow/7hM35ehLSz8Z71gdedJR0jupp6uo39dTAXf3oIr+tGaeh9CZ6DT+JEoTiP85S2nT9JVfpavLBEuw7JHzseB0h6hb6fCoUFe1pFNP8pnUjrWvXTL+gu9YN8IF3HSBbcEJF85/VMNDraXYoFsowhzyWNbXjH7UU98frrCCEmalwq5Re+GIKroqimyeac20V/47OnUXotNj1Jdiui45EBCByMebLsa6KvR6TUlVeJoscULopk9VvnzmMXnEQtKpkiqfMJL+qC0yl/7i8gpF0zWhn9JV6zKebnGSHH+t356/nMSg6iocelJobCzEX6BM0bbZ7T2J3mlKxL4qAtOaaW/TE52Jm4N0FXIg4BOYMnv2bP9zID1lypRRR48+8dgtP7jlqKOdyteEmttrmfnuMt0MukVz3aJmzmbm6YvuIlUsMYzSNa9XV8xYc76dTHmsRVxGU5Pa0J54K5L0VAIdeMeHIlg6NN2H+eCds3Z85/tH+Zn/ah1loUf5AcFpncPgdLNH5w2uDpAAumlB77JuDuI+3SJBAgIQgMDkBNDNyRliAQIQGBYBdHNY8aa3EIDA5ATQzckZYgECEBgWAXRzWPGmtxCAwOQE0M3JGWIBAhAYFgF0c1jxprcQgMDkBNDNyRliAQIQGBYBdHNY8aa3EIDA5ASq0c2n/lTyh3An7wAWIAABCDRMoBrdvOO23zTsN81BIEoCjzz4SJT9iqxT1ejmNVf/VM/VRoaG7kCgeQI/v+qG5hulxaIEqtFNtfqjcy8r2jblIQABn8Cdt9x18UUX+Tmku0mggG6G3930vTPP+tllP+9mJ/EKAt0n8MdZf/zigV/ovp94KAIFdHMsr0/tdcBP/u0nY4tRAAIQSBCQaB7w4f1mzXowke9/DA9c/JKk6yZQ4P2bciXwRjxz9H0f+MAW79/qjeu9YaGXL2SZJCAAgUwCUsxrL7vua8eekHnUzxyabgbUpnUUxXRTUQx0xo+x0hLQRaculsjkIwQgYAR+cf3PwmNMK6lE62LhO9NAOiA1raOoUTcbIEsTEBgIgdaVonnOXdbNwvObA4xf82cMLULAJ8BF59PoQrqwbsppotiFyOEDBCDQFoEyuilfkc62Aka7QyPAtdbBiJfUTfWEcHYwnLgUGQGusm4GtLxuqj8EtZtBxasICOji4vrqbBwn0k31iuh2NrQ41l8CKGbHY7dgJf65MAf2DVTSCkYgED0BFLMXIZ50vOl30o09CbzPpFPpHXbcuVP+4IwjYBcO105fTonC+9770jH8TBDQ3cBSSy395JN/SuTzEQLdJBC4f239Cwbd7OY5U71Xdha2fs5V3zcsxkjAzth051o/h6u8T093j5yOEAicgh3xEDcg0CMC6GaPglWNq2hoNRyxMmAC6Gb8wUco448xPWyWALrZLG9agwAE+k8A3ex/DIv3gBFocWbUgMA8AujmPBZRppDIKMNKp9olgG62y7+11tHT1tDTcP8JoJv9j+HoHiCOo9lwBALlCaCb5dlREwIQGCYBdHOYcZ/Ta0ajw409PZ+MALo5Gb8O10YWOxwcXOs3AXSz3/Gb0Hu0dUKAVB8mAXQzzrgjiHHGlV51gwC62Y04tOcFCtsee1ruKwF0s6+RC/iNFAbgcAgCkxNANydniAUIQGBYBNDNYcU7s7eMTzOxkAmBUQTQzVFk+pqPCPY1cvjdHwLoZn9iVaenqG2ddLEdGwF0M6qIIn9RhZPOdJUAutnVyOAXBCDQVQLoZlcj07hfjFUbR06DfSWAbvY1cmm/Eb40E3IgUAcBdLMOqn21ifL2NXL43SwBdLNZ3rW1huTVhhbDEEgSQDeTRKL5PHv27HBfVGBsmbAFjkJgmATQzQjjXkgQE4UZt0Z4QtClqgmgm1UTbcOeiV1CBPP7wsAzPytKQmBBEMRBYHLhcxZMguPAQi8gUAcBxpt1UG3a5uSiaR5XaMpskoBAZATQzcgCSncgAIHaCaCbtSOmAQhAIDIC6GZkAaU7EIBA7QTQzdoR0wAEIBAZAXQzsoDSHQhAoHYC6GbtiGkAAhCIjAC6GVlA6Q4EIFA7AXSzdsQ0AAEIREYA3YwsoHQHAhConQC6WTtiGoAABCIjgG5GFlC6AwEI1E4A3awdMQ1AAAKREUA3Iwso3YEABGongG7WjpgGIACByAigm5EFlO5AAAK1E0A3a0dMAxCAQGQE8r7vndeARxZ4dYeY9jSmvFu69cCN0U0urdYjhAMQSBCwqxIBTZBp7ONI3bTYNOYKDUEAAoUIuIsU9SwErZLCGfObCoaLRyUNYAQCEKiVAFdrrXgzjSd1kxhkYiITAl0mMGekM2VKlz2MzLf5dBP0kUWX7gyKANdvY+Gep5tAbww6DUEAAr0mMFc3Ec1eRxHnIeAIcCE3cybMG2820x6tQAACtRJAOmvF64zP2YeUE/SKK660yds3ftOqqzfgFk1AAAI+gSeefvLeB//rwosv9DNJt0VgijZ/jdXNd262xac+svemr1+rLS9pFwIQEIFHnn3yjJ9cfPRXjxlLI4JNnQFdar134/cuHPLpg/95u12mLrTI2FBRAAIQaIDApb/6xUHHHT5r1oOBtlpXloBvOQ/1WDc/+YkDjt/jwJz9pBgEINAMAUnnjnvvGmgL3QzAmfxQaF1IE5qHfmivydvAAgQgUC2BbdfeUDeCAZuBwVqgFodyEgjp5p4f3oPb85wcKQaBhgnsseX7Gm6R5oxASDe3fss7rBwJCECgUwRWWGLp7d+3fadcGo4zId1c9ZXThwOCnkKgdwRmrPS63vkch8Mh3Yyjh/QCArESWPYVS8fatY73C93seIBwDwIQ6BwBdLNzIcEhCECg4wTQzY4HCPcgAIHOEUA3OxcSHIIABDpOAN3seIBwDwIQ6BwBdLNzIcEhCECg4wTQzY4HCPcgAIHOEUA3OxcSHIIABDpOAN3seIBwDwIQ6BwBdLNzIcEhCECg4wTQzY4HCPcgAIHOEUA3OxeSbjr08DN/etm6K+rvmAvP7KaHbXn1keMPFpbtDtmnLQdot3kCrenmRb+8wV2H9u/vHvtDVf0/+T8uMLP9Paf3P/UY14uzrr+8KjKl7Rx/3umqu9UWW+2z9Y6ljURZ8RMfmPPe9SuuuqILYYqScAc71Zpupllc+5tb0pklcv77xb98+wdnlKhIlVEE9CX37TO/raO7brvT4gu/fFSxYeavv/JqRxx0mPr+1e+crHNvmBCG1usO6WZVYnf1b2+77757hxbIWvv7vUvPl30NNj/wlo1qbagx47qtrnAsv8la68lznXXnXNf+nUFjDIfcUId0U6fdVb+9bfJgXH/bTZMbwYIR0GBTN6H6qMGmZZLwCWjI+fGPflw5/3L4QZoI9g+RjpJAh3RTfK+//T8npKyz1t1RTmiH6kbADTZXWWXG5m9cxzJJJAh8eMttXc73r2XImWAT4cdO6ObOO+zs0H715BMnnCG65ObrLUpm1nJIFCVgg82Pf3gPZjYD9DTk1DyGChxx3JEMOQOg4jjUCd3c5C0bGs2Lb7ne0iUSNkmqqfqpi04tYYEqPgGb9Nhu/Y39fNJpAtu9c2uXec0dt6aPkhMTgU7o5mKLLPrp/T/lsF73y1+U5qvpUVsRclP1pU1RUQS0M8xNemjkPn3JZWASJvC+9TZ2BbSwHi7J0b4T6IRuCuLGa73VoTzvh+eV3sj5o5//1BnRHZPum/oem9b9t51h/g1B61511gHNY7ivf315a36js37i2OQEuqKbW7xxHa08uP7Y5Vqoe/6KkN0xFbJA4QQBm/RYd5XVE4f4mElg7VXXcPm/uueOzAJkxkFgwe50QysP2sYhf3S57v/uHYs65k8q2R1TUSPukY+9PrNfouJpJ3xDObtvPHcCK3F01EdnTXdtNnugktqwsvZqa2y2xro13flqsuKxp58wl4Si3HrOzQ/c5dzWTfobpr3aDI5NZDKspNdaM9T0930PPaj1Q3NDX7ef3nP/aa9YVl+9ltlWwrYcyMODdmAlra041N5uh3Rz0zet57qry1UXf9HL4JKfzt3/oXulEkqhRzOdamcid0q61wL7SUDHqqcub+1/HmXNtknJz8ovLWmWib4mK07+9BElUDgCt957p0uss/pamUzSmX7riaN+rz+8+XvDQqwHTF35G8673M23COmpl1+gpeqEWX3U2eK6rP7us/Meo04bPVafWV11FVbf7N9uneV/LJQWbX3NaK5JtW65/+5RzhSySeEOEujKfbrQ6FqynUNFN3JKZ93ebNl57wabFQKt6VQ9PTJK5hKmdJnpqk5k+h9lbcN/+kAeaxqSfOSoz1S4Z0XSb6IpkmcfesIkQ9prbrze9WvaUsv6HcxMqxd6vYW1nlnGZarXb952YzcmDRTzD2nkK6SZqucX0wmwzR47CIKf2XzavmaKnsPNu0qLpQl0aLypPrx343e57+qitzl2jhZdEdIFf8gpx5nmSm60BpK4t5Uo3/vwgyaFGgpNW2a5g7f/aBq6rO38mb3srjxtTQU0n6ChsWtR/+6/wAISuNKjQvPh8+ecLGjuo0ayX95Nhsv/Jz+NyaorvCZsSF8Vfq9VWKPyVaev6C/NSSi1U8IFVwWksH886E+ZDBNtyfhGO8+dHnG35AnLWoHRZKL1XWH68wt/yWM50VBVH2dMX8mZ+tFPLp8wClW5hJ3KCXRovKm+aXrIVofyb+TUTZxdNkVXhPSaHxOIc0856+zPHqPb8ISK6W5L8633/+QWGw5r7KNBUDoYsmaiKe1IW9MAUPYvOfrUr3zxOFddresONG0qf466r7GeEZDlyS/Xux99yDmgcITvqRNfFZLsP/3sTvXRF02ZUo5o/OiMH1p8xTDPqFPfas4T8fztD65MW9Yj8+qv7uj1lelKynJ61Ckl1Q24/VlhmbVMl3BGSv+73mtf7+rqTBCc0nao2GUC3dJNCdaH3reT42XzlWPx+Qqr9Zax5a2AtM/m3XT9hF9aIck76p8OtLo2/Wc50i+zJvHSFW6H0gkJsUmnrvPSF5gq6mbfxnHqRYkltbR7Gl+7zDevOWZyM/FVIQlLfOv4xvUNdN4Jp5l0atSp4aRfIJG+7vZb3LeavtLCPCXTmsw1NdSoM2w50VCFH9V9c8O+fiq0j6kuEOiWboqI7VfXBZM5pktTM4XVYKfQjJ4uS2dNA8nwZemKybh7Y5g+3nbn7QlPtA5gObttEhJNV0xlTEH8zQBmZGxC0vDu/Xez8bJGc3l6MdasCtz3+wdcsVVXWiVQXvfI9lUh+Hla1+hV0mk2v3XJuZZOJ/SNosyxX2muoqJz9L4HmZGwZStWR2K1GXOHnP7GhjoawmZbBDqnmxo42Ne16VqAjrTVhMM2zwfK+4duuf1W9zH/vu5XLrWMq/LrmUndfN5792JgzGUOqMw2W86VV+2tsfycCXVcCyxuWkD6++tLr69w9fbhRx92blh/M7267PorXb4c0N6AzDLpTEmnpNDlS3bD3446GfLIsbOWsNzWkPOVL62klQhrGhc5HSTQOd0UI5ujPPfi83XzG6Zm2qpLt5BwyLIJrnb/hVuxo3ok1KVtHtMO+YmxbrvCq7xqJZd49PHH/Opj05oZtNUSKct/nHxOeBZyrMFEASNj/U0U0Eepks0PaAdlnq8KM6KVNxtrX3bjNZafTtjJkD6UmeNv3S33AEWm2UKZiy3yclf++T//uVBFCveFQBd10+YopU16CXEApeRJ2uoK6NINlMw8pFGP+3v98q/KLJDOfP6FkVeCv+7sT7mmjViORlJuLUJrJpY5NuHvN9J+8gn3G6Wb8ydbl3/F0ukCLsdXJV+tRpX38yWyeszB5WjdOfA1U8KyZgyc5fRciu9DfWn7srFhe31tYbkVAl3UTU1UubfAioi9jyeTzpynR156tbupbWbJdKYuXcmW+8s/Kxq489KIz2YYtOKRZ7E47dXYHO03sh1RonTyPgcXGuiNta8Cz/31xTzFTJWkUyV8WHfG6q4VRfDuEatD4lnCso3iNRwOKHKePpYrs9hLPyViw/ZydqjVWQJd1E3B2nidtzlkmv/yhz8JjvbyJClIfu1LGMn/UQM92+6TWUvPq1i+pFPbgyp8v4MkQFvufQeuv/GGABzzpGjCn6hdfomlRlW3m3TTqVElM/Nf7z27ec/D2Y/o2AJLpoVRmf7T9I88+9SoYvXlT11kkfqMY7kLBDqqm/5GzlFrzf78mulsVUylRxowuj89oud+i8YGeqNa0QSrFrXtqJTlQ/vurroaJMqU9s/boaIJ+XPAyUfZ4rWrrpGa+5nJotYmL+/rdf7ZYb9dDSRtP+zzL2TPYtsNr19xbHoFT+sfffrJseUpAIGiBBYsWqGZ8rqotJHTbUPRNqPMFdXLbrrWOaMVhvDWyzw+a1VXox7/mZZ0Ld02brbBxmH1lHRqh7x+LME574z4g0QZcWsdmZ1KN6qcOW+y8F4OojlZ81NKqreE5DeVaT+R+dwLL1jO1JduOS3HJfx7+cAcaKJW4qO9WFpP+CQOuY/h1fzMKsr0b+39sfOo8uRDoCiBjuqmuqGNnEf8vTeaJLp5j7sSz5/4K0K2wlC08668RoK+KvlGpMi23OS0Kc99t2YM9HSK/mR5juS99Pijs6zuuGkvvU5CM4OfeM9OY2cYzIL8+c6RJwqFJnO1EcrN7WpCYN1LV69wPd2/zfQ1yCfj69HUhRb2D5H2v3igESWB7uqm28jpJEabjRK66f/Yr71IqWiEdLN56He/ZvN0qq55Ug3fEk9AFzVr5Z3U6hEaNeRmG6RxdlQJCaL+dGufZweVBqra1+30UVL71c8dpddYOGt6GLGSh9x938JpW/pQMX/sGa41kKP+l8pAujy0bnZ0ftOFwfbupTdy2jq7lK7cUGvOMstXjzDR1FOPerBay9MSu4RGT35OSOZkVn/adaRWdKNtU3syLvkbO/WpbkoZ/Z5Kau3hJX27TPiQ+6g++vOYfhl/jFl6DvG5Pz/nbC760oZHvwml//hUmee7/TV0X98Txuv7aJvVbI9qfW1huRUCndZN21qkG1J/I6dWhGyFpPSKkITGDWbFXW+F0GPdo+5Jqw2MWpGAJl5y8eljD/Wv9kSLup3P3G+0z9Y7ahDqCms6daz4JsyO+hhYQ7cq/txCuacJ1V/70rKN4mbfJR770+OJnDwf/TX00nOveRoaW2bl16w0tgwF+kig07qpi1PjLIfVBpj6aDuu9X1ub9guSt82zGv0V/kAM48zGjDak9r6YghslR+10UcS7D+RLfEdNTzM44+V8deCHh29j8eGzIE9rWYznfD3bGpiJF1AOdpolZkfzrz1vjutgL+2bpl1J2yYPH356XW3hf1WCHRaN0XEhpP+Rk773RutuZcbJGrE6hZV1EShJ1Iee+qJzDhpvcjtVdK/mQUyM3XfbQ+3/OquOzLLhDNlQbrvyqhHmq4Nl89zVEjtBjOwxGEv6NUUbWCwPKpF/4VS/l5Ov7x6FH563S9sadNxKXu508NMlUvYfbre01rOArU6TqDrupneyKm7UZO8975t03J8/Zn7QpeWvQU90a5/PyhRThwNfLSxZOln8nTXb+KrO9/0qycDrY86ZK+PC9yD2wM/MhIYLGc2IZ21Lz85HwiBvX8g0046U5Zt+4Epe7pYrTl33Xu3s19uH1WtvmG8EgJd101dUYk3ctqP/Wo04a+TFMLhD6Pyj5U0qLQp0URz/ojJv09MFEt/HLXlO10ykKN3EdlEZyWvnjTFsVvOdOtuw4PL10au/BhVxX9ANvwWK83bFpp88BW89EaLdGcL5dhJUu6JgEJtUbgVAl3XTUHx38gp5bIVofwvf0uT9YeH/opTuqTl6Oo94usj374hfbepWHsfqNUNJOwp73LPFDrLat1/xFPbkgqpWNo9W6i558H70kctZ9dtd3Jp3QEc98MzLD+c0Hjc9mNJ7sfuwco/+eBbzrnRIuf3ln6ByuZh9PxYoIP+3Ya9+z1QnkN9JNAD3dS4xpYgTLk0AVdoXjIRG3+54HuXjn9bnURTV6/UwYZ1CYP6aFOxGm6ELy2rq43xtqZsN+x2tFBC6mMvkJcD+VUssxV7xFvuBSRYj2lZaHR3rO5kWvMzJSv6MSLL+dwe821otXyXcPMP8iEPT8XIflRD1T+85bYJa/7HxRdf3H20NzT7RydJ3/PI7111naKB+YdJmqBu6wR6oJtiZENLm9ksvSLkiOuE9jc/HnrmSQF10CBXr1XX1asrwV+/TixZ+CKiu0s9kx6wKTf818FJjif5GnCd0laqoirmKqb/1QSILQ3577FPl9Rvh1hJjSLDvdbctP8LbhL68E4GfZc46RRPvdMkcMOuWGg3rt0gj7W8/HLTXF90+5JH7tMdH5VjK4c2vzSqJPn9JdAP3Uxrit28l0a/y6Zz37UuC7p49Euzun78K1OXonJ0g6Z3czi91jOOvqDozcEq4K/DfHaXvU1ENP5a5h2r62hiW6Uz+8YPv8t/zl1yXMnYJKFifneKgrKnV+23hjItaK+Y/5NBrtfCkvhSUY7eDqUd/vbNp++tPD+FpOdQ3RhfMXrtluuleepbTWKtWJho6g59rOW1V13DuiO5t3vwQtshzIKfsImXtWe80c8nHROB7j5n6VOWpmjcYeukupDC4xS/7qi0Lng94GiPKup6tkm3zCoq7BrVOELDH1fGVbGrVKoqEdHdol3DvjhmmpXOOjnOPFo0U53yn7/U3EKhNyL7zdnv2c4Rgnfv6B9KpNO9DpNUde2d0jaAhJ3Mj+qRfnBNr6R2SMfy1HmS5+c83c2BTZJkNl0iU3cYZpPJzRIA+1KlH+NN0fRXXe35ywkpa07Q//3YUdZ08+v/eo+e0rEloHQViYgeiLSpxnQBP0djrl9896LJvwN8m+qUTUHknBn0q1tadtzYWUbCEw6qol7rx41tJ6kZSSeETjBziqarLumUcetU2qbL0bepvtvyiKYrr28UORwI5aiGAvk2pyH5ruQGItAWh1okMCXQth6mDhyN6ZBupbVRMfFWJF2HEujAOz6kJuFrQzenWq5NDJEkRu4dS4W0oxXauil2zucfHspP9Vr/Joackie9MEXLTVLYsX3RVKbbNZFoV8DnbGCa/xVTjqd2/Ejox1quu4BmDNxdUc53tUzoz2k/vfiAz39qlJHZs2ePOtSL/ClTRqpT613rx3163WF2l1xRIQuLpnx2Bu0uvu5eVG7f9j/qWab8cFzJ3W/NdRteyGcBd8bzDyoL2Z+wsGRdv5UkI5LyLoj4hN2heoBAb+7TA33gUE0ENDZ0t7Ea/U2yxFSTe10za+82tHe2ds1D/KmKALpZFck47dguyFG/VhJnt0v1yl49Y+/xKmWGSj0ggG72IEgtuqg1K7cNSJO/LbrR/aY1Hndzslq/0kJW9x3Gw0kIoJuT0BtEXfcwpfZpaafkIDpcqpP6RSlXz98XXMoSlXpAAN3sQZDadVFbHd0spx5IbdeTzrauwabb0stgs7MxqtYxdLNannFac7Oc2nnOkDMzwG6wqWV0BpuZfOLLRDfji2n1PdIsJ0POUVhtsKlldGY2R1GKLB/djCygdXXnszt/TKY15MzzaqK6nOik3ePPO11+afUs/xbXTvYDpwoQGLkjXzae/Pnvpi60SAFjFIUABBok8Nkzvvb1b540qsHWH6oZ5VjO/C4/LxQab942696cPaQYBCDQPIG77run+UZpUQRCuvmLmbfCCAIQ6CaBW2fd+9Nrruqmb9F7FdLNo796zD1/fDh6BHQQAn0kcMaPL+ij23H4HNJN9fBfvn7Uc399IY6u0gsIREPgyPO+fcY5oR906vvkZscjNUY3dSPwiRMPZ9TZ8Sji3nAIaBwj0dS94HC63MGeTtH3UmDdyjw+5NMH77jRVqu+crrlkIAABJokIMW87ne//s4Pv5dnWjOC8WZAl1rvXV7dtPNj+/dtP3WxqfaRBAQg0ACB8F15woHWZSXhT7mPXddN9SrgYrk+UwsCEGiLALpZN/m585txgK4bFvYh0H0CXMsNxGjMulADHtAEBCBQFQFEsyqSYTvzdBPiYVIchUDHCXAJNxagebqpJuHeGHcagkC1BLh4q+UZtjafbqoo9MO8OAqBDhLgsm04KBm/A+xiwAp7w5GgOQiUIIBiloA2eZUM3XRGUc/J4WIBAvURQDHrYzvWcvI+PVFBsbH/Eof42DsC73jHxr3zGYd9AnYxKuHnk26YwJznhRpukuZaIaCJl4UXXviFF3hLSyv4abQwgcBUYeuqhW4WDmdPK9hZ2Po511OAuN0wATtj0+22fg6PuU9Pe0xOHwkETsE+dgefIdAuAXSzXf4ttI6GtgCdJuMigG7GFc+s3iCUWVTIg0B5AuhmeXb9rYmS9jd2eN4FAuhmF6JQow9IZI1wMT1UAujmUCNPvyEAgbIE0M2y5Hpej3FozwOI+20SQDfbpF9324hj3YSxP0wC6OYw4z6n16jqcGNPzycjgG5Oxq/DtZHFDgcH1/pNAN3sd/zwHgIQaJ4Autk88w61yJi0Q8HAlf4QQDf7E6siniKIRWhRFgLFCKCbxXjFVxqFjS+m9KhuAuhm3YRbsI8UtgCdJodEAN0cUrTpKwQgUAUBdLMKij23wfi05wHE/aYJoJtNE6+7PUSwbsLYhwC6yTkwhwBqy3kAgfwE0M38rHpQEvnrQZBwsf8E0M3+x5AeQAACzRJAN5vl3eHWGKt2ODi41i0C6Ga34jGJNwjfJPSoC4H8BNDN/KziL4nyxh9jelgFAXSzCoodsFFC8mbPnt0Bx3EBAv0jgG72L2Z5PJYm5pHFdJkS+pvHH8pAICYCC8bUmcH2xRe7tBSGsbjyvoVweY5CAAKMN6M6B4qKpnVeFUvXNSMkIDAQAow3Ywh0VZJXlZ0YmNIHCIwmwHhzNBuOQAACEMgigG5mUSEPAhCAwGgC6OZoNhyBAAQgkEUA3cyiQh4EIACB0QTQzdFsOAIBCEAgiwC6mUWFPAhAAAKjCaCbo9lwBAIQgEAWAXQziwp5EIAABEYTQDdHs+EIBCAAgSwC6GYWFfIgAAEIjCaAbo5mwxEIQAACWQTQzSwq5EEAAhAYTQDdHM2GIxCAAASyCKCbWVTIgwAEIDCaALo5mg1HIAABCGQRQDezqJAHAQhAYDQBdHM0G45AAAIQyCIQ1fve+ZGcrBDPy1t++eUfffRR+wwuQ+ESvO4+AYSPowhMieBc4fofFV3yyxGI4KIo1/FO1Qpc160HqN/jzQDZTp0BONMvAu68av3i7Be0QXnb4/lNRHNQZ2rzneUEa555X1rsq25yTvflDOu1n5xmvQ5ffc73Ujc5m+s7IbCcIMDJlgDCRxHon25yHnPiNkyAU65h4N1vrme6yRnc/VMqSg858aIMa+lO9Uw3S/eTihCYkADSOSHAmKr3aR9SzhN3++3fv9FGay+/3D8uP22JmEJFXyon8Nzzf73nv/74+OPPnHvuxbNmPVi5fQzGSqBP+97H6qYU8zMHbr/OOtNijRb9qonA88/9zze/+7ODDz5qrH02dY5FVFWBwPXeehTi0c1DDvn0kYdtU1XMsDNAApde9rv377BvuOOtX7Fh92I6im5WEM0ARFnXSPP8HxxQQTOYGDaBsdKJbjZ2ggQu+daj0JvxZgCiAvnQAz9afoXFGosoDUVMYM99zjzj9LNHdbD1K3aUY/HlBy751qMQw3r6Jz/5CUQzvsumrR59cIeNAk0HLuZALQ5FRiAG3VzrTa+LLCp0p0UCm26yUout03QvCMSgm69fZblesMbJvhDQdHlfXMXPVgjEoJutgKPRiAlMXZy58ojDW0HX0M0KIGICAhAYFAF0c1DhprMQgEAFBNDNCiBiAgIQGBQBdHNQ4aazEIBABQTQzQogYgICEBgUAXRzUOGmsxCAQAUE0M0KIGICAhAYFAF0c1DhprMQgEAFBPr03uIKuluziUcefu6qa+9+9I/PHHH4cYmmPv0v+6+6ygorTFtyi3fyVGiCDR8h0DMC6GY1Abv5lkfO/sG13z7tjFHmvvqVk+3Qd7593PbbrTV18X+wnF4nPnHAOa7jR3zxoC98bqte9wXnIZCHAPfpeSiNKfPZQy7a4B27BEQzUX/Pjx+0xDJbXPjvv03k8xECEOgFAcabE4Xpuf/+n08c8J3zzvuhWfn4Xnusu/aM9dddabXVlrZMFbvwktvvue8Rf9S50wf318378Ud/wIqRgAAEekEA3ZwoTL5o7rzzDocctKMvl2Zat+R7fGS9BRZY74C933nSt35q6qnEYostwr2tgSIBgV4Q4D69fJjOOPsWG2lqmPmDs/fNFE2/gRWmT9UA8/x/mzfXqRUkbth9RKQh0H0C6GbJGOnW+4SvzF0F2mqrd33zpN3yG9r+/W/0pfMLh39D1vJXpyQEINAuAXSzJP+bf/mH++6711Xefbeti1qRdGpy09WSHc1+FrVAeQhAoC0C6GZJ8nfd+5irucoqMySCJaxortNqXXPtbZYmAQEIdJwAulkyQPfe9wdX881vXqOcCc11ainJ1bV50nKmqAUBCDRJAN0sSfvhh+aONyf5TYV1113dmtezRpYmAQEIdJkA+5Amjc5z//18aRPrr7uynh1y1adOXSinHa2/P/f8C9o875d3z3FusenrNYz188emtStAZRLWlOMc+/v2qbE2ihW4664nb771QU1N+KNsTXd85l/24DnUYigp3RIBdLMk+OmvmuZq/vrXd2g1vNxDk+uvt4L+8nsgjUsLnKtue0IloJo5zaOe//qNGz796cNHte4a2vPjcwS0KvWUYp78rSsyH6zS4phrUZsTDj14l0JYRnWBfAjURID79JJgZ6zyalezmdVw3cV/+COnjBJNvw8S0Fe/9r16Xt7PTKSlX+/Z7tiAaPrl1aieQPdzyqWv+ul/vXGtHTJF0zd4xRVX6qFVabqfSRoCnSLAeLNkOHSLbTWlLKut+v36hkiSuQ/sdKhte1K7GgOuturyfosait76q3tNlSQ9V/z4O5nvXpIEf/bzp0uenP9am9ps03US7xmRxmnDgAmrzE6btvQkzzUlRsruaVR/GKsWb/nV/fYeKTX9/J95S4idYiS6RYDxZsl4SLN08Vvl+oZIkjlfNHUb/uyfrpLi+KIpN5SjvffSSnPpk5/6SuZa09EnXGKiqe33esxJdRPzDBLcf95voz/cf5mt+EvRwmNYazedkCbaSFnzmHJSrvqiqSpqUbr829t/6Lfo5l7TBsmBQLsE0M3y/A/5zHZSAauvIdL/+7KN9W4kXe2ZgmUlCyUkczbS1DBTj2kmNM63JvWxJ5FU68wf3OgfVVraZ2NSWQvvPNUk6XFH7WoWbr71AUvnT2jy96RTLnLlheun/3FC5ijYFdCDqtJxk06pbYUk8/tMSQiECaCbYT6ho5KVi84/SusYfiFNL+pq1wyjNPRLx14xoYZq6dxkTiPNxBjNb9fS/pNIGiQmnuD86XW/dSWlTXmsqY96q6arcuutd1or+RN6FMqGt8KVZ8HqmyftaVTT0p+/aUpCoCYC6OZEYDU+OvfsT331q1/MtCLZmlBDzzrncmdZI7VDP7tNZivpzN0//A7LTDzBecvNM90hzWlamXBi+Vcu6Qpo50C4ZOZRe4pf+jv2vSfOggbU9uhqWvozWyETAk0SQDcnpa2LXFOB/9/frtdtr91gpo36GqpBqJZ60mUSObqntpGa9jYGbs8TFSVP5ol+tMOOauxpBrVT0vLDiamLLeIK2HRBuLx/VDObVuujH97APxROa9RsQ86E9IcrchQCDRBgPb0yyLrt1Z+m59xqhsZZJhmJNtwiiaTtI7tsEZjss/lEDTa13p0wEv4oy25EaarnykvcXWK1VZcNW7Cj2mNv6aIJe4pfkwx57tB9+5tv/lan8nrfs15d6h8iDYF2CaCb1fN384bu34CG6mkZ/UlQdAOeOZa0+cRt3rtFZoGA65lyLCPOq0DF9KG/y1Y6O1eOdUG/SZergldotRlznyy463f/5WWThED7BLhPrzcG0in93f3b03Qjr5Xu9Eyo1pE+9JETM1eN7THEEqJTVa+0/9yeRCph07qg3aZFq6+w/D+6Khp1Jla3ipqiPASqJcB4s1qeIWtu088/73e9Vsm14GNTjUocdOhiusH3K/tKWkJ0fFM502pRP2LsCmf+lHFOO1bM74L2t1p+icRzz/216Ii7RCtUgUBOAuhmTlBVFpOA6u9fv/FWeyBH4zJNR/o30Y889pw1OXWxl1m6woTWne6659HE+zUS9rU4o3lG8zNxNPzxuef/Fi6Q/6hoFJ0ezW+ckhAoSgDdLEqssvJahZ+62JyNSs6i1pF83fSbqVw3Nes6atlKa1Bau3etO39K//xRhbrp0yANgdYJoJtthkDCdOuv9nA727X4rs1JmTscKxQg3TsfdOj3bNpRnXePiieedq8Eii/3emSTAWMlVDHSBQKsCxWOgqRHzwK5P7dcXtiEV2GzjedtMLrrnsftyArT5r1Gsyrd1OrK3vufaqKpRSo96u4eFU887W5uTJLwddOfdpjEJnUh0AUCjDcnisJzz/91ovoLLLDaqsuZBX+npD860yxkJbr29W9eY4tRN/6sxhc4uR75XXjk0WcXWKDwViQjQwICnSLAeLNwOPwXsz/2x6cK15+/gj8om//IAvbMT4kdlJqUdCPi179xLzN77g8ucWntfq9EiM3yqIQ98/PIY/MeWxpVmHwI9IUAulk4UtoQo8UTV+1Hl11VuP78Ffwb2MSzPfbrQ2ql6AZG0yn72ThNntrzS4WePjJT8zue69Nqb3idK2cb4HNV+3shzYGY9Bftfv5WKAmBEgTQzRLQFtADPK6alEiPYJcx8VId3YO/lJzvnl2Z9mpktVL0GW3TKRNff5K00F7Iq6/+T/OwaOIta6/iqmhStejrO/UaZle3xONSRf2kPAQKEUA3C+GaW3jzjdewavZyScvJn9Awyl4XpDFsYjFdt9J2n6ti+cdcUihb/Nli09WcP88996I5lt+U7vdtStSq509ssdncgbmqnP2Da/NXVBfsBXo+7fwWKAmB+gigm2XY6ulvUzTJSukfwznq+B/ZvbPtmvQdstepqZgK+4cC6ZNPvdQd1QypabE9tqhDV10zdygXMKJD2jnwhcO/ES4TPqqBrb2+UzqYfyuodUGcM5+1D7fLUQjUSgDdLIn3gH0/YDX1OE0J6dSb4e3R71FvPNJjRbY6pMJ5tj3pZck22NRbkczJFZZf3NJ6ynPskNPt9JRe2zeEVS+U8F8ft9MH989zt+53wb45CjVKYQjUSgDdLIlXgyD/JR2STv3eZM65ThXTz0maaMqDr5/4L6PmHPVLFbYMpYeLpLajJE/5OqoXfbou6U1L/kjNH/rNeSL+C+eNsqPqGhi+892fkf6q6eO//DFjlEf1rLBLaDeSvbxOOXpQPTzq9LugPfnuof6ETT5CoF0C6GZ5/npQ0pdOqcxW79lTS8AaFeov/WZi6YXytTFIxfxJQ70nyRe4hEPSHf28hEmn1HaJZbaQHV/C1JZylG9arFFq+v3w/tBPd83rbbi/amlcaS3KpnKk6RoYugmEM7/7Bd3pW+tSPRUoOrjWY1F2t662ZFzfMbJj7SrhuiA41gWNc/ULTn4Z0hDoCIEps2fP7ogrYTemTJkyqsAtN567zjpz39U4qkx9+Ro86pcjbZqyUEOShkMP3iXPVkrJiv/jveFWJJr6iZ7MAay8lWqHq9tR+yVh3TjbMNYd1WvxrJh+Xd2t4UgcA78VLLXN/34QkfnWyfv4O+etuQYSe+5z5hmnnz2qob5cMqP870t+4JJvPQSMNyc9izRU1Os1dStaaB5Q0qYqP77kc3lEUy5q0KfC/g3vKL9VRq+kyxRNVZG3elJorKtyTz/Ja6PgT35iM/9Hj0c1Hc7X8FxCLMvhYjqqUbw625ZojnWPAhBgvFnlOaAZQ7fRMvPlbLrbdYvm2nY+StfyeOPucO1FSq6Kxnr6AbVRb1RKm9XAUxvaE29Fkp6+/32bBN7xoQ5O4rlzQ7MB2rX67xdf509W6JDkcupiC+XvQrpTVeUw3qyK5CR2ujzeRDcniSx14ySAbnYhrl3WTe7Tu3CG4AMEINAnAuhmn6KFrxCAQBcIoJtdiAI+QAACfSKAbvYpWvgKAQh0gQC62YUo4AMEINAnAuhmn6KFrxCAQBcIoJtdiAI+QAACfSKAbvYpWvgKAQh0gQC62YUo4AMEINAnAuhmn6KFrxCAQBcIoJtdiAI+QAACfSIQg25O/iPmfYoYvtZPIPASufobp4UeEIhBN6//+e96QBoXe0Lgnnue7omnuNkagRh089xzL37+uf9pDSENx0Xg3AtuCnSo9TfmBnzjUGMEYtDNWbMe/OZ3f9YYMhqKmIAGm0cf/dWIO0jXKiEQw/s3HYh//+Ep2773DZVAwcgwCTz6yPMbbf5JfQ0Hus94MwCn2kO8f7MCnmPP1/fvsO/xJ17NDXsFrAdp4rbbHhsrmoMEQ6czCPRmvCnfA98/1rN3vnPzTTddf9N3rDZjlaUWm/oPlk8CApkEdGN+732P//jKX+ZZQx/75Z3ZBJnlCASu99YD0SfdFP0AynKxoRYE8hNo/XLN72oEJQMXe+uBiGFdKIJThC50n0Dr12r3EQ3Hw57pJufucE7NTvWUE69T4WjdmZ7ppnhxBrd+0uAABAZOoH+6qYAhnQM/axvuPudbw8C731wvdVNYOZW7f27F4SFnWhxxrLYXfdVNUeCErvZUwFqCgE4wzrEEEz46Aj3WTXWAM5vzuCYCKGZNYOMwu2AE3XCneGC3VwR9pAvNEEAum+Hc91Zi0E0XA8748Lmo75V3vevdV1xxebgYRyEAgbEEeva80Nj+UGAUARuP8wUzChH5nSJgZ2zaq9bP4X7Pb6aBkpNJIHAKZpYnEwIQCBBANwNwOAQBCEAggwC6mQEl7izGnnHHl941QADdbAByy00glC0HgOajI4BuRhfSHB1CSXNAoggERhJAN0eiieMAEhlHHOlFpwigm50KB85AAAI9IIBu9iBIdbjIOLQOqtgcCAF0M+ZAI44xR5e+tUcA3WyPfdsto6ptR4D2+0oA3exr5Mb6jSyORUQBCJQjgG6W40YtCEBguATQzeHGXj1nTDro8NP5sgTQzbLkul0PQex2fPCu3wTQzX7Hb3LvUdjJGWJhaATQzQgjjhRGGFS61CUC6GaXotGSL+hsS+Bptq8E0M2+Rm6U34jgKDLkQ6AqAuhmVSSxAwEIDIUAujmUSIf7ySg1zIejEPAJoJs+jd6nkb/eh5AO9IEAutmHKDXiI5rbCGYaiYEAuhlDFF0fEL54YklPuk0A3ex2fPAOAhDoHgF0s3sxac8jRqztsaflPhFAN/sUrYCvacmbPXt2oLwOjS0Qrs5RCAyWALoZZ+hzaqKKJUqm9TdOQPQKAhMQQDcngNeZqr7YpaVwrJsJ6RxbngIQGDiBBQfe/5i6P4n8ubq+/sZEhr5AoFoC6Ga1PNuxNoli+h5XZce3SRoC8RHgPj2+mNIjCECgXgLoZr18sQ4BCMRHAN2ML6b0CAIQqJcAulkvX6xDAALxEUA344spPYIABOolgG7WyxfrEIBAfATQzfhiSo8gAIF6CaCb9fLFOgQgEB8BdDO+mNIjCECgXgLoZr18sQ4BCMRHAN2ML6b0CAIQqJcAulkvX6xDAALxEUA344spPYIABOolgG7WyxfrEIBAfATQzfhiSo8gAIF6CaCb9fLFOgQgEB8BdDO+mNIjCECgXgLoZr18sQ4BCMRHAN2ML6b0CAIQqJcAulkvX6xDAALxEUA344spPYIABOolUMvvWfJzsvUGrSLrhKkikBWY4ZdEK4DYoInKdJOLsMGo0VRsBOzyQUB7EdoKdNNC3osO4yQEukzAXU2oZ5djJN8mnd9ENDseYNzrIwFdVlxZXQ7cRLpJaLscWnzrOwGur85GsLxuEtTOBhXHoiHAVdbNUJbUTcLZzXDiVXwEuNY6GNMyukkgOxhIXIIABBojUFg3Ec3GYkNDEHAEuOi6diZUsA8ps0srrrjShhtsnHmITAhAwBF47I+PXHPNVXloSDrZnJQHVDNligUjz/ferrvssclG75mx8lrNdIBWINBrAv/3uSd/fceNXzjswLG9GJpuBtSmdRQV6+ZXjj/tretsMfYMoAAEIOATeOKph7537jcuvuSHfmYi3bpYJPyp++NQdPMbJ31vrdU3rJsm9iEQJYG//e8LH9t7m1mzHgz0blDS2WXdLLAuFOiGIr33XgcgmoEznkMQCBN42f9Z5OgvnhIuw9GOECigm2GPt9lql3ABjkIAAmECr15hVS0PhMtwtAsEqtHN9223wz9OXboL/cEHCPSawJprrNdr/wfifDW6+ZrXvHYgvOgmBGolMG25V9VqH+OVEKhGN5dccplKvMEIBCAAge4TqEY3u99PPIQABCBQFQF0syqS2IEABIZCAN0cSqTpJwQgUBUBdLMqktiBAASGQgDdHEqk6ScEIFAVAXSzKpLYgQAEhkIA3RxKpOknBCBQFQF0syqS2IEABIZCAN0cSqTpJwQgUBUBdLMqktiBAASGQgDdHEqk6ScEIFAVAXSzKpLYgQAEhkKgrt9l6z6/22be8MkDd/f9vOj865db+tV+Tun0T66/4MgjD7LqW2yx1eGfO9U+dicRK4TvnHPMWWd9W5w/85nDttvqo90BjidxEGC8OS+OM393y7wPE6T+9j9/Oe+8MyYw0GZVILRJn7Z7QgDdnBeoqsTut3ffdt99986z23jqi8fus8GmK+rv57f8R9HGo4FQtOOUh0B+AujmPFYSu7vuu3Xe57Kp22feVLZq+/WA0H4M8KDzBNDN+UL0mztunu9z8Q/PPvcnN7NWvGpXagChK5HAj64SQDfnRGb77Xd2ATrl1BM1OzlJsH756+utupm1nC4nzNshQ+hygPCtOwTQzTmxWGftt1tIfnn7DZYukbD5Qa3kLrro1BIW2qoChLbI027vCKCbc0K28EIv33efT7ng3farn5eOoqZHbUVozdV79sOEQCgddyoOjQC6OTfib1pjfZe68MLzHn/yD+XOgxtvvtpV1IbNFaevVs5Ii7WA0CJ8mu4RAXRzbrBWW2XdVVaZ4T6U28Porwhtusl7enQSmKtAMBQkIBAggG7Og7Pzznu4DzZHOe9YjtSdd99mpd6y1kaWzp/Qdkv9ua2X/r8uP7+dSUq2DmES56kLgWYIDPc5yzTfNd8wd0bS7WHU4CtdJpBz7XU/dkc1Vfqyf3h5oGT6UOK5zESBzx28r8s59phT3r7euxNH9fGSK8484YQj0/lW0Q7deO0sS2cmGoagLfpXXXWFPBnVtUwnlanvFXfo+2df3scpkVH9Ir8XBBhvzguTHk63vThF9zBqRchd/zL31vU2m2d0XEpzqdIO/2H2QA3poJ68DhSY/FArECZ3GwsQaJIAujkf7bdv8C73uegeRtPZQitCmhI97fTjTHCl2hp2XXvlnRoV2t93vnXBYYcdZ15qU71Gl/axjkTDEOroAjYhUCsB7tPnw/vG16+j1SG3l0gbOTNviuer8PcP2iovnXX5hVaELrzkdBPNr3/trHXWzJgV1XSB/t7y5o3P+v7XtNavVnRLrk1O/s2pXvnjv/Wn9M2v60LDEFyj/AuBHhFgvDlfsDQvue22O7ksm6+cr0TWB3+r/OqvXyerSEberIfvsicyNczMFE2rtsTUZXbf5UD7eN8Dd1q68kSTECp3HoMQaIAAupmEbPvVNRKUtCUPZ302hdWKkAQuq0hG3sw75762TrfneQa2sqxnkJyhu+66PcNidVmNQajOZSxBoDkC6GaSte5/NUfpck3akoW8z9JWu9e2fePe8ZHJmTPnvnvJf8BxZOm/H3jFksu6AnfcUa9uNgYh3F+OQqCbBNDNjLjYHOWll54/9jUfpq2aGM2/dUlmTW1fscTSGU5kZelRSJdtT3NmlaomrwEI1TiKFQg0ToB1oQzkNkcpedJLiAMzj5I/aaszscdHD8iwNTpLc5ru4CuXe/XoUvMdefGvE72raT5b4z40A2GcFxyHQBcJMN7MiMqcRZjdP+4OhF9CrBUhG/qZ0GRYTGVp7UVzmu4v/5Toww8/kLJUV0YDEOpyHbsQqJkAupkNeK013+YOaMlbuyyzCy2wgL08STqbX/5GWQvn65ki2+0ULlnV0Q5CqKpr2IHAJAS4T8+m5+9h1IPnmevdetTHbaiUCZOYbHMFc6XU9rT70888kfkMZUGTZYq3C6GMx9SBQCME0M1szG4PoxMsbTPK1M2bb7vWVdaKUGAONLuB+XO1KP/IY7/X6NWEeP7jcz5plX/99TfO+URmunqJnIYhlPCQKhBohQC6ORK7v4dxtw/f5T+fozr+ipC9Q2ikrdEH9K6jM848ySZJ/YKSY1trcsKtnzv3CzSQbgZCAx2hCQhUSADdHAnT7WF0u4W02Sihm/6P/do7hEbayjow532dLz066Y5rknTVGWuuMO01ibayajeUVzeEhrpBMxColADrQiGcgT2Mts4usdM7hEJWso5puHrSqUfYXbne3KHXeey528EaV3ZHNJ3j9UHIApMrT/RylaMQBOohgG6GuNrWIreR04pqRcgeLS+3InTFNRfYvne9QXLLjXfUZKLZ71SiPgilu/nsfz9Vui4VITA5AXQzxHDUHkb7IQ1NQWrROWRixDHbLa/d710bYCZcrg9CoqH8H595duTOsPxGKAmB0gTQzTHobDjpb+S0H9LQy5NKjBM1XLWFoEK/qPH0s0+Mcbeew3VASHj6wot/TuQEPj782KzAUQ5BoG4C6OYYwm4Poyvk9lT6P/a7/jqbjqmfddh/XLKQ7N588/VZ9mrPqwOCc3rq1MVd4umnCnwltMWhdtA00BMC6OaYQLk9jK6Qe1+c/div3v9WYkVIpl58cd6yRv4lDm1CsinRMU5XfbgOCM7HZZeZ5hI/vfrynF63yCGnhxSLngC6OT7E/h5GXbS2IpT//W+JNpZcYt47OrWfKXE086M2LZ3yzcK/LFTo5jezXcusHIKzPH36yi6hiYucbzu9/Iq5L1Ix30hAoGEC6OZ44Fq3sd9rM/HSilChqUm/mSUWX8o+SgXGDjndTk8pi70Y1KpnJuzm96GHKnsPSOUQnOevW+kN1oWrr7vU0qMS+m0lN+jOiWKUHfIhMAkBdDMXPRta2npOuRUh15hue+3N7VKBc847KSCdGuF+6rO7aaenlHqvjx1k7gZGZ3bzq6GxnkeyKhMmqoXgnPF/PlPehn9y7twLT3ZPvmoTwrRp0yfsDtUhUJoAzwvlQpceWtp9a676qUIbbbC1va1DenHTTTfokUrtlLSXKrkn1jWjanOahx1yolRG6um0e5ePbC350J249n4mzK/yujUsJ/ET6mN/P90qphOVQ3BNbLfNrrb/X0z0GnzttPdR6EtF7+szFO5nRe65d2baQ3Ig0AwBdDMXZ40Q9dtB9ho33SROuOlS+qgf+N1z77mSJylMCFzCLRV2LWqca4LrqqR1Uy8ZkbiYGCVMlf5YOQTnifqlLwDrvr4n7Ksi7aqeztpt52Lvh04bIQcCExLgPj0vQP+3g+zRw7yVs8rpRzX0pNDYeTop4EXnX2+/wLHVZjtKO7LszZd34D7HSIzylJyv2rgPlUNwDerpUn0xaCgdbl8/laxHUSXf4WIchUDdBKbMnj07ZxtTpkwZVfJLR35t0w23G3WU/DABbQh9+tknE29Fkp5KnQPv+NDda3wKoslc7e1PvCtPD+8vsvCiiVf5qaTbBuvf0Yc59+LoHx6550O7bTXK1fxX6ygLPcoPCE7rHLhPb/9EcmPJhC6MdSs+0VSX3WtM0zMPaRoTvvA0bZAcCOQnwH16flaUhAAEIDCHALrJeQABCECgGAF0sxgvSkMAAhBANzkHIAABCBQjgG4W40VpCEAAAugm5wAEIACBYgTQzWK8KA0BCEAA3eQcgAAEIFCMQDW6+cwz/N5LMe6UhgAE+kugGt38/e/v7y8CPIdAdwg89vhD3XEGT0YRqEY3L77kh//3uSdHtUE+BCCQk8DMO27JWZJiLRKoRjfVgR9d8f0Wu0HTEIiAgF7q8b3vnxFBR6LvQgHdDL+D5FunnXT7nb+InhcdhEBNBP72vy8ccvi+NRnHbLUECujm2Ib3O2DX/7ztqrHFKAABCCQIPPHUQyd/84hZsx5M5PsfwwMXvyTpugkUeP+mXAm8Ec8c3XWXPTbZ6D0zVl7LckhAAAKjCGhh4Nd33PiFww4cVcDyh6abAbVpHUUx3VQIA52xACux4oorbbjBxn4OaQhAIEHgsT8+cs01eW/RWheLhPN1fwxITeso6tLNupliHwKDItC6UjRPu8u6WXh+c4Dxa/6MoUUI+AS46HwaXUgX1k05TRS7EDl8gAAE2iJQRjflK9LZVsBod2gEuNY6GPGSuqmeEM4OhhOXIiPAVdbNgJbXTfWHoHYzqHgVBwGur87GcSLdVK8IbWdDi2P9JaDLiiury+GbVDfVt47HeLPN3tnlAOBb5QQ23PAdldtszGDHr6bGOHS8ocL7N/P0J7DxKk/1assstdTSTz3Fu5qqhYq1igkwukwDDchI67hq0c00grZyDH3roNsiMLR2iXg0EbdQpnvU+uVcwX16ulcdzAnEoIPe4lI5AkS5HDdqFSUQs25yFRU9G2IqT/RjimbX+hKzbiZYcyElgPARAhAoR2BAulkOELX6QiD9vZjO6Utf8LPjBKLVTa6Zjp95uAeB/hKIVjczQ4KYZmKJIJPIRhDEHnUhTt3kKurRKVirq5wJteIdrPE4dTMQTi6kABwOQQACeQgMTjfzQKFMvwiEvwvDR/vVU7ztCIEIdZPrpCPnFm5AIFYCEerm2FAhrGMR9agA0exRsKJxNTbd5CqK5tSssCOcFRXCxJQIxKabOYPKhZQTVMeLEceOByhW96LSTa6iWE/TyfvFuTE5QywYgah003qVJ8GFlIcSZSAAgTSB4epmmgU5/SJQ9JuvaPl+0cDbJgnEo5tcFU2eN7QFgSETiEc3S0QRqS0BrSNViF1HAjFMNyLRTa6iYZ6+RXvNeVKUGOUzCUSim5l9y5PJhZSHEmUgAAGfwNB102dBui8EJvm2m6RuX/jgZ90EYtBNroS6zxLsQwACPoEYdNPvT4k0slsCWotViFeL8GnaEei9bnIVcSoXJcA5U5QY5RMEeq+bif6U+8iFVI5bR2rNnj27I57gxkAIxKabuoTGXkVjCwwk9n3sZvobbmw055wQKWFN2+kjDXxui8CCbTVcSbv+2Z++NgJNuMJ+9UBhDnWTABHvZlyG4FUk481Cl5DFVbWsIhpqWDqbsBj5gSvkrYW7UC0KQyBBoN/jTXVm8ivBWbBrMgGIj10jMGHECXfXAtpHf/qtmxNeQn7AKjTlmyVdIYEKY1ShqQo7iKm+EIjkPr0vuPETAhCIgAC6GUEQ6QIEINAoAXSzUdw0BgEIREAA3YwgiHQBAhBolAC62ShuGoMABCIggG5GEES6AAEINEoA3WwUN41BAAIREEA3IwgiXYAABBolgG42ipvGIACBCAigmxEEkS5AAAKNEkA3G8VNYxCAQAQE0M0IgkgXIACBRgmgm43ipjEIQCACAuhmBEGkCxCAQKME0M1GcdMYBCAQAQF0M4Ig0gUIQKBRAuhmo7hpDAIQiIAAuhlBEOkCBCDQKAF0s1HcNAYBCERAAN2MIIh0AQIQaJQAutkobhqDAAQiIIBuRhBEugABCDRKAN1sFDeNQQACERBANyMIIl2AAAQaJYBuNoqbxiAAgQgIoJsRBJEuQAACjRJANxvFTWMQgEAEBNDNCIJIFyAAgUYJoJuN4qYxCEAgAgLoZgRBpAsQgECjBNDNRnHTGAQgEAEBdDOCINIFCECgUQLoZqO4aQwCEIiAALoZQRDpAgQg0CgBdLNR3DQGAQhEQADdjCCIdAECEGiUALrZKG4agwAEIiAQv26+4x0bRxAnupCfABHPz4qS5QgsWK5ax2vNnj274x7iXrUEiHi1PLEWJhD/eDPcf45CAAIQKEoA3SxKjPIQgMDQCUzhBmfopwD9hwAEChJgvFkQGMUhAIHBE0A3B38KAAACEChIAN0sCIziEIDA4Amgm4M/BQAAAQgUJIBuFgRGcQhAYPAE0M3BnwIAgAAEChJANwsCozgEIDB4Aujm4E8BAEAAAgUJoJsFgVEcAhAYPIHY3usxZcqUPDHlKak8lCgDAQhkEojnOcucipmggIAmgHTwYyKyVYUsYdY6XpV9M0jCCKSZV067gSbUnRjGm2lSFqexCVe38uCNbZcC7RLIPGc4DeoOighnkq+v3Zpi2u/5TcWgkjBUZae+8GO5QgKZ50xNF1iFbkdpKjMWpXtarbWAGz0eb45llL4SwlV0NF0lwI5DfSSQeQ4Q9z6GskWf+6qbmWe/4xi4BuzQqOpIZ4vnYgNNZ8bdzooGHKAJ0c6MQh1k6otsL+/TR3EXppykAiVHGa8jrthskkBmZHOeME36ObS2MuNSAkJVdvI03T/dzKQT0MEAhVG1MpsI2OFQ9wlkxhTRbCVwzWCvtZX+6WY60hMCmrB62h9yukYA0exaRPruT890M30BVKJ6aSPphvoe6WH6rzhmhjId8WHy6UivM2NUyLfJLRRqrk+6mUZT69mfbq4QWQq3TiAzgjpnaj1tWu91LxyoOwR12++TbtZ6QtQNulbnMZ4mMEo00yXJgUBRAj3WzcqVrnKDRYNB+aoIIJpVkWzMTmbIcrY+Sd2cTSSK9UY3m0cjUq00mogQH4sSyIwaX4pFMdZdvr6I1GfZmPRGN81jl6gJTU1mE87zsT4CiGZ9bOu2nBm7sY2WqzXWbLhAX3Uz3CuODpNA5iXEd+GgToZmwt0P3cy8Hpo5G1psupkORtNKZqSauYqiYdhwR/obnX7oZiKcteKu1XiiI3ysigCiWRXJdu1kxjHgUtHyAVOFDvVSNwv1kMLRE8i8ePj+60Xcqw1TtdYCANHNABwO9YAAotmDIEXnIroZXUgH0yEpZqZoCsCo/MGw6XFH88cuf8nKcaCblSPFYBMExl4zYws04SVt5CBQ1c11VXZyuLwAupmHEmW6RSCnJuYs1q2+4U0fCKCbfYgSPnoEMtVQY40mhxueOySrJ5AZ4kQziTINRx/dTISDj/0jYNeMJawPiavL8kl0ikA6cJ1yL+0MuplmQk6fCIy95JDOPoXzJV/DUQsffclGjf9HN2uEi+m6CaRFM50jH1q/zOrmEIH9zMDl7NckdXM2kSiGbiaA8LE3BEZdLZn5SGdv4toHR9HNZJS4wJJEOvk5UxzN0/BRK0aiywRGXYmj8pvsSy91swvgmgwSbSUI5JHFdBlOmwTGrn1MhyyPh+Vq5bEcKNMP3WwFjaPWYtOBsA350CQRQTqHfOZU2Pd+6GaFHcbUcAhkKizS2aMTIB2sRE5miBvoYF91M4GvKlI1ma3KPewUJZB5XRHlohgbK58Zr8Zaz99QX3Uzfw/9krpg3H9+ZiDdlygGusAhgsg5UDmB3uhm+uyXApbGkVk3M7N0E1TsDoFqT57u9CtKTxLB8q9KP62+J0o2SaM3upkJJcExs4xlJgrro5/jp60KiYgJEPGIg1t31/qkmxN+vWRWD1w8meXrjgf2ayKQGc1A9GtyA7MlCLgwdSpYfdJNEU+f/YVopqvLpiykjWSWLBFyqnSHQGZM06HvjsOD9SQzUgkaecokqlT4sWe6mdnzQqe+cLdLPLMLZDZDgNA3wzn6Vvqnm5mn/pwRY5FlokwjFuzwUStGoo8E0sEtdOb0scsR+JyIUTqIDfexf7opQKOozdHOfOoZKDbKeMOBobkmCQTOhybdoC0j0PHLsJe6KbgBrHO08+//WQws8dKR0AYmlbHyJKIkkHnyEPcoY11Tp6ZknkM1NVa52frO9V5jqZxzuwYTUa4qNAmzro9VGW+XWDStdzZGfR1v2lleyYmeNqKAZcYsmjOSjqSDDhMI5CTQb910ndQFUPoasLqZFpDOnKdRT4ulg07EexrKht3u9316Glb+8z59zchaZvXMkummyYEABAZCIDbdrCRsvnoimpUgxQgEYiIQw3165fEwrbRE5U1gEAIQ6C8Bxpv9jR2eQwAC7RBgvNkOd1qFAAT6SwDd7G/s8BwCEGiHALrZDndahQAE+ksA3exv7PAcAhBohwC62Q53WoUABPpLAN3sb+zwHAIQaIcAutkOd1qFAAT6SwDd7G/s8BwCEGiHALrZDndahQAE+ksA3exv7PAcAhBohwC62Q53WoUABPpLAN3sb+zwHAIQaIcAutkOd1qFAAT6SwDd7G/s8BwCEGiHwP8PBkOwqdjv9FsAAAAASUVORK5CYII=\n",
            "image/jpeg": "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\n"
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "puvoJQKeWFQj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}